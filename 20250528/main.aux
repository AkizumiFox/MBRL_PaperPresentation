\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\babel@aux[2]{}
\@nameuse{bbl@beforestart}
\providecommand \oddpage@label [2]{}
\babel@aux{english}{}
\@writefile{nav}{\headcommand {\slideentry {0}{0}{1}{1/1}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {1}{1}}}
\bibstyle{plainnat}
\bibdata{references}
\bibcite{schneider2025surprisingineffectivenesspretrainedvisual}{{1}{2025}{{Schneider et~al.}}{{Schneider, Krug, Vaskevicius, Palmieri, and Boedecker}}}
\bibcite{zhang2025efficientreinforcementlearningadaptively}{{2}{2025}{{Zhang et~al.}}{{Zhang, Ma, Hao, Guo, Chen, and Yu}}}
\@writefile{nav}{\headcommand {\beamer@sectionpages {1}{1}}}
\@writefile{nav}{\headcommand {\beamer@subsectionpages {1}{1}}}
\@writefile{nav}{\headcommand {\sectionentry {1}{References}{2}{References}{0}}}
\@writefile{nav}{\headcommand {\slideentry {1}{0}{0}{2/2}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {2}{2}}}
\@writefile{toc}{\beamer@sectionintoc {2}{The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning}{3}{0}{1}}
\@writefile{nav}{\headcommand {\beamer@sectionpages {1}{2}}}
\@writefile{nav}{\headcommand {\beamer@subsectionpages {1}{2}}}
\@writefile{nav}{\headcommand {\sectionentry {2}{The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning}{3}{The Surprising Ineffectiveness of Pre-Trained Visual Representations for Model-Based Reinforcement Learning}{0}}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{1}{3/3}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {3}{3}}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{2}{4/4}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {4}{4}}}
\citation{schneider2025surprisingineffectivenesspretrainedvisual}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{3}{5/5}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {5}{5}}}
\newlabel{fig:pvr_dreamer}{{1}{6}{\textbf {Components of PVR-based DreamerV3 (left) and TD-MPC2 (right) architectures.} In DreamerV3, the output $x_t$ of the frozen pre-trained vision module $g_{\textrm {\ding {100}}}$ is given to the encoder $\mathrm {enc}(z_t \vert x_t)$ which maps its input to a discrete latent variable $\textrm {z}_t$. In TD-MPC2 a stack $x_{t-3:t}$ of the last $3$ PVR embeddings is given to the encoder $\mathrm {enc}(x_{t-3:t})$ which maps the inputs to fixed-dimensional simplices. The encoder of DreamerV3 additionally requires the recurrent state $h_t$ as input. The rest of both algorithms remains unchanged}{Doc-Start}{}}
\newlabel{fig:pvr_dreamer@cref}{{[figure][1][]1}{[1][6][]6}}
\@writefile{snm}{\beamer@slide {fig:pvr_dreamer}{6}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{4}{6/6}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {6}{6}}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{5}{7/7}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {7}{7}}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{6}{8/8}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {8}{8}}}
\newlabel{fig:data_efficiency}{{2}{9}{\textbf {Normalized ID performance and data-efficiency comparison} on DMC, ManiSkill2 and Miniworld environments between the different representations. Each line represents the mean over all runs with a given representation, the shaded area represents the corresponding standard deviation. Solid lines represent DreamerV3 runs, whereas dashed lines indicate TD-MPC2 experiments. Especially in the DMC experiments, representations trained from scratch outperform all PVRs also in terms of data-efficiency. Curves of each environment individually can be found in Appendix}{Doc-Start}{}}
\newlabel{fig:data_efficiency@cref}{{[figure][2][]2}{[1][9][]9}}
\@writefile{snm}{\beamer@slide {fig:data_efficiency}{9}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{7}{9/9}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {9}{9}}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{8}{10/10}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {10}{10}}}
\newlabel{fig:bars_performance}{{3}{11}{\textbf {Average normalized performance on DMC, ManiSkill2 and Miniworld tasks in the OOD setting.} The baseline representation learned from scratch outperforms all PVRs, even in the OOD settings. Thin black lines denote the standard error}{Doc-Start}{}}
\newlabel{fig:bars_performance@cref}{{[figure][3][]3}{[1][11][]11}}
\@writefile{snm}{\beamer@slide {fig:bars_performance}{11}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{9}{11/11}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {11}{11}}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{10}{12/12}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {12}{12}}}
\newlabel{fig:properties}{{4}{13}{\textbf {IQM return of different categorizations.} Each marker shows interquartile-mean performance. ViT and diverse data representations excel in OOD settings. Sequential data helps in ManiSkill2 and Miniworld but not DMC. See Appendix for individual environment plots}{Doc-Start}{}}
\newlabel{fig:properties@cref}{{[figure][4][]4}{[1][13][]13}}
\@writefile{snm}{\beamer@slide {fig:properties}{13}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{11}{13/13}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {13}{13}}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{12}{14/14}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {14}{14}}}
\newlabel{fig:dynamics_error}{{5}{15}{\textbf {Dynamics Prediction Errors} on \texttt {Pendulum Swingup} (200 trajectories). DreamerV3: KL divergence between prior/posterior distributions. TD-MPC2: MSE between predicted and encoded latent states. Error bars show standard error}{Doc-Start}{}}
\newlabel{fig:dynamics_error@cref}{{[figure][5][]5}{[1][15][]15}}
\@writefile{snm}{\beamer@slide {fig:dynamics_error}{15}}
\newlabel{fig:reward_error}{{6}{15}{\textbf {Reward Prediction Errors} on \texttt {Pendulum Swingup} (200 trajectories). Error is $\vert r_t - \hat {r}_t \vert $. Error bars show standard error}{Doc-Start}{}}
\newlabel{fig:reward_error@cref}{{[figure][6][]6}{[1][15][]15}}
\@writefile{snm}{\beamer@slide {fig:reward_error}{15}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{13}{15/15}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {15}{15}}}
\newlabel{fig:umaps}{{7}{16}{\textbf {UMAP projections of DreamerV3 (top) and TD-MPC2 (bottom) encodings} color-coded by reward. Points show states from \texttt {Pendulum Swingup}. Scratch-trained representations better separate high/low reward states than PVR embeddings}{Doc-Start}{}}
\newlabel{fig:umaps@cref}{{[figure][7][]7}{[1][16][]16}}
\@writefile{snm}{\beamer@slide {fig:umaps}{16}}
\@writefile{nav}{\headcommand {\slideentry {2}{0}{14}{16/16}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {16}{16}}}
\@writefile{toc}{\beamer@sectionintoc {3}{Efficient reinforcement learning through adaptively pretrained visual encoder}{17}{0}{2}}
\@writefile{nav}{\headcommand {\beamer@sectionpages {3}{16}}}
\@writefile{nav}{\headcommand {\beamer@subsectionpages {3}{16}}}
\@writefile{nav}{\headcommand {\sectionentry {3}{Efficient reinforcement learning through adaptively pretrained visual encoder}{17}{Efficient reinforcement learning through adaptively pretrained visual encoder}{0}}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{1}{17/17}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {17}{17}}}
\citation{zhang2025efficientreinforcementlearningadaptively}
\newlabel{fig1}{{8}{18}{APE pipeline for MBRL. Training consists of two phases: Adaptive Pretraining (blue) and Downstream Policy Learning (yellow). The first phase uses adaptive data augmentation on real-world images, dynamically adjusting augmentation probabilities. The second phase integrates the pretrained encoder as a perception module in the RL framework}{Doc-Start}{}}
\newlabel{fig1@cref}{{[figure][8][]8}{[1][18][]18}}
\@writefile{snm}{\beamer@slide {fig1}{18}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{2}{18/18}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {18}{18}}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{3}{19/19}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {19}{19}}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{4}{20/20}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {20}{20}}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{5}{21/21}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {21}{21}}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{6}{22/22}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {22}{22}}}
\newlabel{fig:loss}{{9}{23}{Loss comparison between DreamerV3, encoder with frozen random initialized parameters, encoder with trainable random initialized parameters and APE. The last layer of the frozen random initialized encoder is finetuned during training. The absolute value of actor loss is used}{Doc-Start}{}}
\newlabel{fig:loss@cref}{{[figure][9][]9}{[1][23][]23}}
\@writefile{snm}{\beamer@slide {fig:loss}{23}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{7}{23/23}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {23}{23}}}
\newlabel{fig:Atari}{{10}{24}{Training curves for Atari 100k benchmarks}{Doc-Start}{}}
\newlabel{fig:Atari@cref}{{[figure][10][]10}{[1][24][]24}}
\@writefile{snm}{\beamer@slide {fig:Atari}{24}}
\newlabel{fig:mem}{{11}{24}{Training curves for Memory Maze benchmarks}{Doc-Start}{}}
\newlabel{fig:mem@cref}{{[figure][11][]11}{[1][24][]24}}
\@writefile{snm}{\beamer@slide {fig:mem}{24}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{8}{24/24}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {24}{24}}}
\newlabel{figpieg}{{12}{25}{Comparison of DreamerV3-based and DrQ-v2-based APE against other ResNet pretrained algorithms}{Doc-Start}{}}
\newlabel{figpieg@cref}{{[figure][12][]12}{[1][25][]25}}
\@writefile{snm}{\beamer@slide {figpieg}{25}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{9}{25/25}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {25}{25}}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{10}{26/26}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {26}{26}}}
\newlabel{fig:init random}{{13}{27}{Choosing suitable pretraining strategy weighs more than increasing the depth of encoder network. We compare APE with random initialized encoder with frozen parameters, random initialized encoder with trainable parameters and DreamerV3. The last layer of the frozen random initialized encoder is finetuned during training. ‘-18’ and ‘-4’ denote the number of layers used in the encoder}{Doc-Start}{}}
\newlabel{fig:init random@cref}{{[figure][13][]13}{[1][27][]27}}
\@writefile{snm}{\beamer@slide {fig:init random}{27}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{11}{27/27}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {27}{27}}}
\newlabel{fig:aug}{{14}{28}{Different choices of augmentation strategy. APE with random gaussian blur as its main augmentation strategy outperforms other settings}{Doc-Start}{}}
\newlabel{fig:aug@cref}{{[figure][14][]14}{[1][28][]28}}
\@writefile{snm}{\beamer@slide {fig:aug}{28}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{12}{28/28}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {28}{28}}}
\newlabel{fig:arc}{{15}{29}{Different choices of network architectures. This figure indicates that APE with ResNet18 achieves better results compared with a deeper APE (ResNet50)}{Doc-Start}{}}
\newlabel{fig:arc@cref}{{[figure][15][]15}{[1][29][]29}}
\@writefile{snm}{\beamer@slide {fig:arc}{29}}
\@writefile{nav}{\headcommand {\slideentry {3}{0}{13}{29/29}{}{0}}}
\@writefile{nav}{\headcommand {\beamer@framepages {29}{29}}}
\@writefile{nav}{\headcommand {\beamer@partpages {1}{29}}}
\@writefile{nav}{\headcommand {\beamer@subsectionpages {17}{29}}}
\@writefile{nav}{\headcommand {\beamer@sectionpages {17}{29}}}
\@writefile{nav}{\headcommand {\beamer@documentpages {29}}}
\@writefile{nav}{\headcommand {\gdef \inserttotalframenumber {29}}}
\gdef \@abspage@last{29}
