\documentclass[9pt]{beamer}
\input{commands}

% Basic packages
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage{url}
\usepackage{nicefrac}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage[ruled, vlined]{algorithm2e}
\usepackage{sidecap}

% TikZ and related libraries
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usetikzlibrary{arrows,arrows.meta,calc}
\usetikzlibrary{patterns,backgrounds}
\usetikzlibrary{positioning,fit}
\usetikzlibrary{shapes.geometric,shapes.multipart}
\usetikzlibrary{patterns.meta,decorations.pathreplacing,calligraphy}
\usetikzlibrary{tikzmark}
\usetikzlibrary{decorations.pathmorphing}

\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
% \usepackage{siunitx}
\usepackage{makecell}

\usepackage[sort]{natbib}

\AtBeginDocument{\RenewCommandCopy\qty\SI}

\pgfplotsset{compat=newest}

\newcommand{\blap}[1]{\vbox to 0pt{\hbox{#1}\vss}}

\newcommand{\enc}{h}
\newcommand{\Infop}{\info_{p,h}}
\newcommand{\Expp}{\Exp_{p,h}}

\newcommand{\x}{\mathbf{x}}
\newcommand{\z}{\mathbf{z}}
\newcommand{\y}{\mathbf{y}}
\newcommand{\w}{\mathbf{w}}
\newcommand{\bo}{\mathbf{o}}
\newcommand{\ba}{\mathbf{a}}
\newcommand{\bz}{\mathbf{z}}
\newcommand{\bs}{\mathbf{s}}
\newcommand{\scoref}{\nabla_\x \log p^\tau(\x)}
\newcommand{\scorem}{\mathbf{S}_\theta(\x, \tau)}
\newcommand{\bbe}{\mathbb{E}}
\newcommand{\Tau}{\mathcal{T}}

\setbeamertemplate{navigation symbols}{}

% Add page number to the lower right corner
\setbeamertemplate{footline}{%
  \hfill\usebeamercolor[fg]{page number in head/foot}%
  \usebeamerfont{page number in head/foot}%
  \insertframenumber\,/\,\inserttotalframenumber\hspace*{1ex}\vskip2pt%
}

% Customize the page number appearance
\setbeamercolor{page number in head/foot}{fg=gray}
\setbeamerfont{page number in head/foot}{size=\small}

\title{Diffusion for World Modeling: Visual Details Matter in Atari}
\setbeamerfont{title}{size=\huge}
\date{February 28, 2025}

% Add the new commands
\newcommand{\repolink}{\href{https://github.com/eloialonso/diamond}{\texttt{https://github.com/eloialonso/diamond}}}
\newcommand{\wslink}{\href{https://diamond-wm.github.io}{\texttt{https://diamond-wm.github.io}}}

\begin{document}

\begin{frame}
    \titlepage % This command creates the title page
\end{frame}

\begin{frame}
    \frametitle{Reference}

    \bibliographystyle{plainnat}
    \bibliography{references}
\end{frame}

\begin{frame}
    \frametitle{Score-based Diffusion Models}
    Consider a diffusion process $\{\x^\tau\}_{\tau\in[0, \Tau]}$ with corresponding marginal distributions $\{p^\tau\}_{\tau\in[0, \Tau]}$, where:
    \begin{itemize}
        \item Diffusion models gradually add noise to data samples until they become pure noise
        \item This creates a sequence of increasingly noisy versions of the data
        \item The process is reversible - we can learn to denoise corrupted samples
        \item Boundary conditions: $p^0=p^{data}, p^\Tau=p^{prior}$
        \item $p^{data}$ is our original data distribution
        \item $p^{prior}$ is a tractable unstructured prior distribution, such as a Gaussian
        \item The time parameter $\tau$ controls the noise level ($\tau=0$ is clean, $\tau=\Tau$ is pure noise)
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Forward Process SDE}
    The diffusion process follows a stochastic differential equation:
    \[ d\x = \mathbf{f} (\x, \tau) d\tau +  g(\tau) d\w \]
    Where:
    \begin{itemize}
        \item $\mathbf{f} (\x, \tau) d\tau$ is the drift term (deterministic part that guides the overall direction)
        \item $g(\tau)$ is the diffusion coefficient (controls noise strength over time)
        \item $\w$ is a standard Wiener process (provides random noise)
    \end{itemize}
    Intuition:
    \begin{itemize}
        \item The equation describes how data points move and get corrupted over time
        \item First term ($\mathbf{f} (\x, \tau) d\tau$) determines the average path
        \item Second term ($g(\tau)d\w$) adds random noise, gradually making samples more noisy
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Reverse Process SDE}
    It can be shown that the reverse of forward process of the SDE is also an SDE:
    \[ d\mathbf{x} = \left[ f(\mathbf{x}, \tau) - g(\tau)^2 \nabla_{\mathbf{x}} \log p^{\tau}(\mathbf{x}) \right] d\tau + g(\tau) d\bar{w} \]
    Where:
    \begin{itemize}
        \item $\bar{\w}$ is the reverse-time Wiener process
        \item $\scoref$ is the (Stein) score function
        \item The score function is the gradient of the log-marginals with respect to the support
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Score Function}
    Intuition behind the score function \( \scoref \):
    \begin{itemize}
        \item Tells us which direction to move our noisy sample to make it more "data-like"
        \item Acts like a guide pointing towards regions of higher probability of being real data
        \item In image terms: points towards what the clean image should look like
    \end{itemize}
    The score function is crucial because it provides the "hint" for how to reverse the noise.
    However, we don't know the true score function, so we need to estimate it
\end{frame}

\begin{frame}
    \frametitle{Learning the Score Function}
    Challenge: We need to estimate the score function but never observe it directly

    Solution: Score Matching - train using only clean images and a known noise process
    
    Key idea: Since we control how noise is added, we can simulate the process
    \begin{itemize}
        \item Generate noisy image $\x^\tau$ from clean image $\x^0$
        \item Train model to predict direction of noise removal
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Score Matching Loss}
    The loss function measures how well our model estimates the score:
    \[ \mathcal{L}(\theta) = \bbe \left[ \left\Vert \scorem - \nabla_{\x^\tau} \log p^{0\tau}(\x^\tau \mid \x^0) \right\Vert^2 \right] \]
    Where:
    \begin{itemize}
        \item $\scorem$ is our model's estimate of the score function
        \item $\nabla_{\x^\tau} \log p^{0\tau}(\x^\tau \mid \x^0)$ is the true score of the Gaussian noise
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Gaussian Perturbation Kernel}
    The distribution $p^{0\tau}$ describes how clean data transforms into noisy data:
    \[ p^{0\tau}(\x^\tau \mid \x^0) = \mathcal{N}\!\Bigl(\x^\tau;\, \alpha(\tau) \x^0,\, \sigma^2(\tau) \mathbf{I}\Bigr) \]
    Where:
    \begin{itemize}
        \item $p^{0\tau}$ is the Gaussian perturbation kernel of the forward process
        \item $\alpha(\tau)$ scales the clean sample
        \item $\sigma^2(\tau)$ is the noise variance at time $\tau$
        \item $\mathbf{I}$ ensures independent noise per dimension
    \end{itemize}
    
    Key insight: We choose a Gaussian transition for analytical tractability
\end{frame}

\begin{frame}
    \frametitle{Simplified Reconstruction View (1/2)}
    The complex score matching loss can be rewritten in a more intuitive form:

    Original score matching loss:
    \[ \mathcal{L}(\theta) = \bbe \left[ \left\Vert \scorem - \nabla_{\x^\tau} \log p^{0\tau}(\x^\tau \mid \x^0) \right\Vert^2 \right] \]

    Simplified reconstruction loss:
    \[ \mathcal{L}(\theta) = \bbe \left[ \left\Vert \mathbf{D}_\theta(\x^\tau, \tau) - \x^0 \right\Vert^2 \right] \]

    These are equivalent to optimize when we:
    \begin{itemize}
        \item Define a denoising function: \[ \mathbf{D}_\theta(\x^\tau, \tau) = \scorem \sigma^2(\tau) + \x^\tau \]
        \item Assume the forward process preserves the clean data mean: \[ \mu(\tau,\mathbf{x}^0) = \mathbf{x}^0 \]
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Simplified Reconstruction View (2/2)}
    Key components:
    \begin{itemize}
        \item $\mathbf{D}_\theta$ is our "d"enoising model that tries to recover the clean image $\x^0$ from the noisy image $\x^\tau$
        \item $\sigma(\tau)$ controls how much noise is present at time $\tau$
    \end{itemize}

    This reformulation transforms the abstract score matching problem into a concrete denoising task.
\end{frame}


\begin{frame}
    \frametitle{Adapting Diffusion Models for World Modeling}

    Key differences from standard diffusion:
    \begin{itemize}
        \item Standard diffusion: Generates random samples from data distribution
        \item World models: Must predict next state given history of states and actions
    \end{itemize}

    Modified training objective:
    \[ \mathcal{L}(\theta) = \bbe \left[ \Vert \mathbf{D}_\theta(\x_{t+1}^\tau, \tau, \x_{\le t}^0, a_{\le t}) - \x_{t+1}^0 \Vert^2 \right] \]
    
    How training works:
    \begin{itemize}
        \item Sample trajectory $(\x_{\le t}^0, a_{\le t}, \x_{t+1}^0)$ from experience replay
        \item Sample $\x_{t+1}^\tau \sim p^{0\tau}(\x_{t+1}^\tau|\x_{t+1}^0)$ using the perturbation kernel
        \item Train $\mathbf{D}_\theta$ to denoise $\x_{t+1}^\tau$ conditioned on $(\x_{\le t}^0, a_{\le t})$
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Generating Predictions with World Models}
    To predict the next state in the environment:
    \begin{itemize}
        \item Start with random noise and gradually denoise it
        \item Use history of states $\x_{\le t}^0$ and actions $a_{\le t}$ to guide denoising
        \item Balance these competing factors:
        \begin{itemize}
            \item Better predictions (more denoising steps)
            \item Faster predictions (fewer denoising steps) 
            \item Computational resources needed
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Diamond Network Architecture (\cite{alonso2024diffusionworldmodelingvisual})}

    Key insight: Architecture choice affects stability with few denoising steps
    \begin{itemize}
        \item DDPM becomes unstable with few denoising steps
        \item EDM remains stable even with single-step denoising
    \end{itemize}
    
    The denoising model $\mathbf{D}_\theta$ uses a preconditioned architecture:
    \[ \mathbf{D}_\theta(\x_{t+1}^\tau, y_t^\tau) = c_\text{skip}^\tau\, \x_{t+1}^\tau + c_\text{out}^\tau\, \mathbf{F}_\theta\bigl(c_\text{in}^\tau\, \x_{t+1}^\tau, \, y_t^\tau\bigr) \]
    Where:
    \begin{itemize}
        \item $\mathbf{F}_\theta$ is a U-Net backbone
        \item $y_t^\tau := (c_\text{noise}^\tau,\, \x_{\le t}^0,\, a_{\le t})$ is the conditioning information
        \item $c_\text{skip}^\tau, c_\text{in}^\tau, c_\text{out}^\tau$ are preconditioners determined by $\sigma(\tau)$
        \item $c_\text{noise}^\tau$ is also determined by $\sigma(\tau)$ to ensure stability
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Preconditioned Architecture (1/2)}
    The denoising function combines two paths:
    \[ \mathbf{D}_\theta(\x_{t+1}^\tau, y_t^\tau) = \underbrace{c_\text{skip}^\tau\, \x_{t+1}^\tau}_{\text{skip connection}} + \underbrace{c_\text{out}^\tau\, \mathbf{F}_\theta\bigl(c_\text{in}^\tau\, \x_{t+1}^\tau, \, y_t^\tau\bigr)}_{\text{network prediction}} \]
    
    Skip connection:
    \begin{itemize}
        \item Acts as a shortcut, letting part of the noisy input bypass the network
        \item Weight $c_\text{skip}^\tau$ chosen based on noise level
        \item When noise is low, keeps most of the input unchanged
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Preconditioned Architecture (2/2)}
    Network prediction:
    \begin{itemize}
        \item $\mathbf{F}_\theta$ ("F"ilter) learns to predict either the clean image or a residual correction
        \item Input scaling $c_\text{in}^\tau$ maintains consistent input scale across noise levels
        \item Output scaling $c_\text{out}^\tau$ properly scales network output for final prediction
    \end{itemize}
    Conditioning information $y_t^\tau$:
    \begin{itemize}
        \item Noise level $c_\text{noise}^\tau$ guides denoising strength
        \item Past observations $\x_{\le t}^0$ provide context
        \item Past actions $a_{\le t}$ inform dynamics
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Benefits of Preconditioning}
    Why use this architecture?
    \begin{itemize}
        \item Stabilizes training across noise levels
        \item Adapts network's role based on noise:
        \begin{itemize}
            \item High noise: Network does heavy lifting
            \item Low noise: Network focuses on residual
        \end{itemize}
        \item Makes learning easier by separating tasks
        \item Enables stable single-step denoising
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Training Implementation}
    The original training loss for the denoising network:
    \[ \mathcal{L}(\theta) = \bbe \left[ \Vert \mathbf{D}_\theta(\x_{t+1}^\tau, \tau, \x_{\le t}^0, a_{\le t}) - \x_{t+1}^0 \Vert^2 \right] \]
    
    Can be shown to be equivalent to optimizing:
    \[ \mathcal{L}(\theta) = \bbe \left[ \left\Vert \mathbf{F}_\theta(c_\text{in}^\tau \x_{t+1}^\tau, y_t^\tau) - \frac{1}{c_\text{out}^\tau} \bigl( \x_{t+1}^0 - c_\text{skip}^\tau \x_{t+1}^\tau\bigr) \right\Vert^2 \right] \]
    
    The training target adapts based on noise level $\sigma(\tau)$:
    \begin{itemize}
        \item High noise ($\sigma(\tau) \gg \sigma_\text{data}$):
        \begin{itemize}
            \item $c_\text{skip}^\tau \to 0$
            \item Network learns to predict clean signal $\x_{t+1}^0$ directly
        \end{itemize}
        \item Low noise ($\sigma(\tau) \to 0$):
        \begin{itemize}
            \item $c_\text{skip}^\tau \to 1$
            \item Target becomes residual noise (difference between clean and noisy)
            \item Prevents training from becoming trivial at low noise levels
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Diamond Training Loop}
    \begin{algorithm}[H]
    \SetKwProg{Proc}{Procedure}{:}{}
    \SetKwFunction{FTrain}{training\_loop}
    
    \Proc{\FTrain{}}{
        \For{epochs}{
            \texttt{collect\_experience(}\textit{steps\_collect}\texttt{)} \;
            \For{steps\_diffusion\_model}{
                \texttt{update\_diffusion\_model()} \; 
            }
            \For{steps\_reward\_end\_model}{
                \texttt{update\_reward\_end\_model()} \; 
            }
            \For{steps\_actor\_critic}{
                \texttt{update\_actor\_critic()} \; 
            }
        }
    }
    \end{algorithm}
\end{frame}

\begin{frame}
    \frametitle{Experience Collection}
    \begin{algorithm}[H]
    \SetKwProg{Proc}{Procedure}{:}{}
    \SetKwFunction{FCollect}{collect\_experience}
    
    \Proc{\FCollect{$n$}}{
        $\x_0^0 \gets \texttt{env.reset()}$ \;
        \For{$t = 0$ \KwTo $n - 1$}{
            Sample $a_t \sim \pi_\phi(a_t \mid \x_t^0)$ \;
            $\x_{t+1}^0, r_t, d_t \gets \texttt{env.step(}a_t\texttt{)}$ \;
            $\mathcal{D} \gets \mathcal{D} \cup \{ \x_t^0, a_t, r_t, d_t \} $ \;
            \If{$d_t = 1$}{
                $\x_{t+1}^0 \gets \texttt{env.reset()}$ \;
            }
        }
    }
    \end{algorithm}
\end{frame}

\begin{frame}
    \frametitle{Diffusion Model Update}
    \begin{algorithm}[H]
    \SetKwProg{Proc}{Procedure}{:}{}
    \SetKwFunction{FUpdateDiffusionModel}{update\_diffusion\_model}
    
    \Proc{\FUpdateDiffusionModel{}}{
        Sample sequence $ ( \x_{t-L+1}^0, a_{t-L+1}, \dots, \x_t^0, a_t, \x_{t+1}^0 ) \sim \mathcal{D} $ \;
        Sample $\log(\sigma) \sim \mathcal{N}(P_{mean}, P_{std}^2)$ \tcp*[f]{log-normal sigma} \;
        Define $\tau := \sigma$ \quad\quad\quad\quad\quad\quad\quad\quad\tcp*[f]{identity schedule} \;
        Sample $\x_{t+1}^\tau \sim \mathcal{N}(\x_{t+1}^0, \sigma^2 \mathbf{I})$ \tcp*[f]{Add noise} \;
        $\hat{\x}_{t+1}^0 = \mathbf{D}_\theta(\x_{t+1}^\tau, \tau, \x_{t-L+1}^0, a_{t-L+1}, \dots, \x_t^0, a_t)$ \;
        Compute loss $\mathcal{L}(\theta) = \Vert \hat{\x}_{t+1}^0 - \x_{t+1}^0 \Vert^2$ \;
        Update $\mathbf{D}_\theta$ \;
    }
    \end{algorithm}
\end{frame}

\begin{frame}
    \frametitle{Reward and Termination Model Update}
    \begin{algorithm}[H]
    \SetKwProg{Proc}{Procedure}{:}{}
    \SetKwFunction{FUpdateRewardEndModel}{update\_reward\_end\_model}
    
    \Proc{\FUpdateRewardEndModel{}}{
        Sample indexes $\mathcal{I} \coloneqq \{t, \dots, t+L+H-1 \}$ \tcp*[f]{burn-in + horizon} \;
        Sample sequence $ ( \x_i^0, a_i, r_i, d_i )_{i \in \mathcal{I}} \sim \mathcal{D} $ \;
        Initialize $h = c = 0$ \tcp*[f]{LSTM states}\;  
        \For{$i \in \mathcal{I}$}{
            $\hat{r}_i, \hat{d}_i, h, c = R_\psi(\x_i, a_i, h, c)$ \;
        }
        $\mathcal{L}(\psi) = \sum_{i \in \mathcal{I}} \mathrm{CE}(\hat{r}_i, \mathrm{sign}(r_i)) + \mathrm{CE}(\hat{d}_i, d_i)$ \;
        Update $R_\psi$ \;
    }
    \end{algorithm}
\end{frame}

\begin{frame}
    \frametitle{Actor-Critic Update}
    \begin{algorithm}[H]
    \SetKwProg{Proc}{Procedure}{:}{}
    \SetKwFunction{FUpdateActorCritic}{update\_actor\_critic}
    
    \Proc{\FUpdateActorCritic{}}{
        Sample initial buffer $( \x_{t-L+1}^0, a_{t-L+1}, \dots, \x_t^0) \sim \mathcal{D} $ \;
        Burn-in buffer with $R_\psi$, $\pi_\phi$ and $V_\phi$ to initialize LSTM states \;
        \For{$i=t$ \KwTo $t + H - 1$}{
            Sample $a_i \sim \pi_\phi(a_i \mid \x_i^0)$ \;
            Sample reward $r_i$ and termination $d_i$ with $ R_\psi$ \;
            Sample next observation $\x_{i+1}^0$ with $\mathbf{D}_\theta$ \;
        }
        Compute $ V_\phi(\x_i) $ for $i = t, \dots, t + H$ \;
        Compute RL losses $\mathcal{L}_V(\phi)$ and $\mathcal{L}_\pi(\phi)$ \;
        Update $\pi_\phi$ and $V_\phi$ \;
    }
    \end{algorithm}
\end{frame}

\begin{frame}
    \frametitle{Experimental Setup \& Results}
    \textbf{Benchmark:} Atari 100k (26 games)
    \begin{itemize}
        \item Only 100k environment steps (~2 hours of gameplay)
        \item 5 random seeds per game, 2.9 days per run on RTX 4090
    \end{itemize}
    
    \textbf{Performance:}
    \begin{itemize}
        \item Mean Human Normalized Score (HNS): 1.46 (>1 is superhuman)
        \item Superhuman in 11/26 games
        \item Outperforms STORM, DreamerV3, IRIS, TWM, SimPle
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Key Findings}
    \textbf{Main Results:}
    \begin{itemize}
        \item Sets new state-of-the-art for world model-based agents
        \item Achieves strong performance with limited training data
        \item Visual quality matters for world modeling
    \end{itemize}
    
    \textbf{Implications:}
    \begin{itemize}
        \item Diffusion models effectively capture environment dynamics
        \item High-quality visual predictions enable better planning
        \item Sample efficiency possible with good architectures
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Technical Analysis}
    \textbf{EDM Framework Advantages:}
    \begin{itemize}
        \item Improved training objective over DDPM
        \item Stable with single-step denoising
        \item Adaptive mixing of noisy and denoised predictions
    \end{itemize}
    
    \textbf{Denoising Strategy:}
    \begin{itemize}
        \item Final choice: 3 denoising steps
        \item Balances prediction quality and computational efficiency
        \item Adapts to game complexity (1 step for simple, 3+ for complex)
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Comparison with IRIS (Previous SOTA)}
    \textbf{IRIS Limitations:}
    \begin{itemize}
        \item Uses discrete autoencoder + transformer
        \item Visual inconsistencies in predictions
        \item Higher computational requirements
    \end{itemize}
    
    \textbf{DIAMOND's Advantages:}
    \begin{itemize}
        \item More consistent visual predictions
        \item Better preservation of important details
        \item Lower compute: fewer steps, smaller model
    \end{itemize}
\end{frame}

\end{document}