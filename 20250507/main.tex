\documentclass[9pt]{beamer}
\input{commands}

% Basic packages
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage{url}
\usepackage{nicefrac}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage[ruled, vlined]{algorithm2e}
\usepackage{sidecap}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{makecell}
\usepackage[sort]{natbib}
\usepackage{bm}
\usepackage{algpseudocode}
\usepackage{cleveref}
\usepackage{adjustbox}

\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usetikzlibrary{arrows,arrows.meta,calc}
\usetikzlibrary{patterns,backgrounds}
\usetikzlibrary{positioning,fit}
\usetikzlibrary{shapes.geometric,shapes.multipart}
\usetikzlibrary{patterns.meta,decorations.pathreplacing,calligraphy}
\usetikzlibrary{tikzmark}
\usetikzlibrary{decorations.pathmorphing}

\AtBeginDocument{\RenewCommandCopy\qty\SI}
\pgfplotsset{compat=newest}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}{%
  \hfill\usebeamercolor[fg]{page number in head/foot}%
  \usebeamerfont{page number in head/foot}%
  \insertframenumber\,/\,\inserttotalframenumber\hspace*{1ex}\vskip2pt%
}
\setbeamercolor{page number in head/foot}{fg=gray}
\setbeamerfont{page number in head/foot}{size=\small}
\setbeamerfont{title}{size=\huge}

\newcommand{\rvx}{\mathbf{x}}
\newcommand{\rvz}{\mathbf{z}}
\newcommand{\E}{\mathbb{E}}

\algrenewcommand\algorithmicrequire{\textbf{Input:}}
\algnewcommand\algorithmiclinecomment[1]{\(\triangleright\) #1}
\algnewcommand\algorithmicplainlinecomment[1]{\phantom{\(\triangleright\)} #1}
\def\LineComment{\algorithmiclinecomment}
\def\PlainLineComment{\algorithmicplainlinecomment}

\newcommand{\ahn[1]}{\textcolor{blue}{[SA: #1]}}
\newcommand{\fei[1]}{\textcolor{orange}{[Fei: #1]}}
\newcommand{\jyp[1]}{\textcolor{teal}{[Jun: #1]}}


\let\ab\allowbreak

\title{Facing Off World Model Backbones: RNNs, Transformers, and S4}
\date{May 7, 2025}
\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}
    \frametitle{Reference}

    \bibliographystyle{plainnat}
    \bibliography{references}
\end{frame}

\begin{frame}{Linear State Space Models (SSMs)}
    \begin{itemize}
        \item \textbf{Definition:} Maps 1-D input signal $u(t)$ to 1-D output signal $y(t)$
        \item \textbf{Formulation:}
        \begin{itemize}
            \item \textbf{Continuous-time:}
            \begin{align*}
                \mathbf{s}'(t) &= \mathbf{A} \mathbf{s}(t) + \mathbf{B} u(t) \\
                y(t) &= \mathbf{C} \mathbf{s}(t) + \mathbf{D} u(t)
            \end{align*}
            
            \item \textbf{Discrete-time:}
            \begin{align*}
                \mathbf{s}_k &= \mathbf{\overline{A}} \mathbf{s}_{k-1} + \mathbf{\overline{B}} u_k \\
                y_k &= \mathbf{\overline{C}} \mathbf{s}_k + \mathbf{\overline{D}} u_k
            \end{align*}
        \end{itemize}
        
        \item \textbf{Parallelizable SSMs (PSSMs):}
        \begin{itemize}
            \item Combines benefits of RNNs and Transformers
            \item Efficient autoregressive generation like RNNs
            \item Parallelizable computation like Transformers
            \item Computed via discrete convolution or parallel associative scan
        \end{itemize}
        
        \item \textbf{PSSM Interface:}
        \begin{itemize}
            \item \textbf{Single step:} $\mathbf{y}_k, \mathbf{s}_k = \text{PSSM}(\mathbf{u}_k, \mathbf{s}_{k-1})$
            \item \textbf{Parallel:} $\mathbf{y}_{1:T}, \mathbf{s}_T = \text{PSSM}(\mathbf{u}_{1:T}, \mathbf{s}_0)$
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{The S4 Model}
    \begin{itemize}
        \item \textbf{Core Idea:} SSMs with learnable parameters for sequence modeling
            \begin{itemize}
                \item Matrices $\mathbf{A}, \mathbf{B}, \mathbf{C}, \mathbf{D}$ and step size $\Delta$ learned via gradient descent
                \item Challenge: Expensive computation of $\mathbf{\overline{A}}$ powers
            \end{itemize}
            
        \item \textbf{Key Innovation:} Diagonal Plus Low-Rank (DPLR) parameterization
            \begin{itemize}
                \item $\mathbf{A} = \bm{\Lambda} - \mathbf{P}\mathbf{P}^*$ with diagonal $\bm{\Lambda}$
                \item HiPPO-LegS: $\bm{\Lambda}_{ii} = -(2i+1)$, $P_i = \sqrt{2i+1}$
                \item DPLR enables $O(N)$ computation of powers and inverse via Woodbury identity
                \item Negative diagonal ensures stability and uniform recall across timescales
            \end{itemize}
            
        \item \textbf{Implementation:} HiPPO initialization, multiple SSMs for vector sequences
            
        \item \textbf{Extensions:} S4D (diagonal $\mathbf{A}$), S5 (multi-input/output SSM)
    \end{itemize}
\end{frame}


\begin{frame}{S4WM \citep{deng2023facingworldmodelbackbones}: World Modeling with Structured State Space Models}
    \begin{itemize}
        \item \textbf{Key Innovation:} First world-model framework compatible with any PSSM
            \begin{itemize}
                \item Works with S4, S5, and their variants
                \item Operates in compact latent space rather than raw pixels
                \item Efficiently learns long-range dynamics in image sequences
            \end{itemize}
            
        \item \textbf{Architecture Components:}
            \begin{itemize}
                \item \textbf{Encoder:} Compresses raw observations into latent representations
                \item \textbf{PSSM Backbone:} Models temporal dynamics in latent space
                \item \textbf{Decoder:} Reconstructs observations from predicted latent states
            \end{itemize}
            
        \item \textbf{Advantages:}
            \begin{itemize}
                \item \textbf{Efficiency:} Lower computational cost than pixel-space modeling
                \item \textbf{Long-range dependencies:} Captures complex temporal patterns
                \item \textbf{Flexibility:} Compatible with various PSSM architectures
                \item \textbf{Scalability:} Handles longer sequences than traditional approaches
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{S4WM Architecture}
    \begin{figure}[t]
        \centering
        \includegraphics[width=\textwidth]{figs/s4wm.pdf}
        \caption{S4WM, the first S4-based world model for improving long-term memory. S4WM efficiently models the long-range dependencies of environment dynamics in a compact latent space, using a stack of S4 blocks. This crucially allows fully parallelized training and fast recurrent latent imagination. S4WM is a general framework that is compatible with any parallelizable SSM including S5 and other S4 variants.}
        \label{fig:s4wm_architecture}
    \end{figure}
\end{frame}

\begin{frame}{Latent-Space Generative Process in S4WM}
    \begin{itemize}
        \item \textbf{Stochastic Latent Variables:} Model future observations through latent space
            \begin{itemize}
                \item Introduces stochastic latents $\mathbf{z}_{0:T}$ to model observations $\mathbf{x}_{1:T}$
                \item Conditioned on initial observation $\mathbf{x}_0$ and actions $\mathbf{a}_{1:T}$
            \end{itemize}
            
        \item \textbf{Generative Process:}
            \begin{align*}
                p(\mathbf{x}_{1:T}\mid \mathbf{x}_0,\mathbf{a}_{1:T})
                =\int p(\mathbf{z}_0\mid \mathbf{x}_0)\,\prod_{t=1}^T 
                \underbrace{p(\mathbf{z}_t\mid \mathbf{z}_{<t},\mathbf{a}_{\le t})}_{\text{prior}}
                \;\underbrace{p(\mathbf{x}_t\mid \mathbf{z}_{\le t},\mathbf{a}_{\le t})}_{\text{likelihood}}
                \;d\mathbf{z}_{0:T}.
            \end{align*}
            
        \item \textbf{Key Advantage:} Dimensionality Reduction
            \begin{itemize}
                \item Factorization through latent variables avoids direct modeling of high-dimensional $\mathbf{x}_t$
                \item Enables efficient learning and inference in complex environments
                \item PSSM backbone effectively captures temporal dependencies in compact latent space
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{History Encoding via PSSM Blocks}
    \begin{itemize}
        \item To capture dependencies in $\{\mathbf{z}_{<t},\mathbf{a}_{\le t}\}$, S4WM feeds
            \begin{align*}
                \mathbf{g}_t = \mathrm{MLP}\bigl([\mathbf{z}_{t-1};\;\mathbf{a}_t]\bigr)
            \end{align*}
            into a \textbf{stack} of PSSM blocks (e.g.\ S4 layers).
            
        \item These blocks compute in parallel during training and sequentially during rollout:
            \begin{align*}
                \textbf{(single step)}&&
                \mathbf{h}_t,\,\mathbf{s}_t 
                &= \mathrm{PSSM\_Blocks}(\mathbf{g}_t,\,\mathbf{s}_{t-1}) \\
                \textbf{(parallel)}&&
                \mathbf{h}_{1:T},\,\mathbf{s}_T 
                &= \mathrm{PSSM\_Blocks}(\mathbf{g}_{1:T},\,\mathbf{s}_0)
            \end{align*}
            
        \item Here $\mathbf{h}_t$ is a fixed-size embedding summarizing all past latents and actions
    \end{itemize}
\end{frame}

\begin{frame}{Probabilistic Components}
    \begin{itemize}
        \item \textbf{Prior}
            \begin{align*}
                p(\mathbf{z}_t\mid \mathbf{z}_{<t},\mathbf{a}_{\le t})
                = \mathrm{MLP}(\mathbf{h}_t),
            \end{align*}
            which outputs e.g.\ mean and variance for a Gaussian latent prior.
            
        \item \textbf{Likelihood}
            \begin{align*}
                p(\mathbf{x}_t\mid \mathbf{z}_{\le t},\mathbf{a}_{\le t})
                = \mathcal{N}\bigl(\hat{\mathbf{x}}_t,\mathbf{I}\bigr),\quad
                \hat{\mathbf{x}}_t
                = \mathrm{Decoder}\bigl([\mathbf{h}_t;\mathbf{z}_t]\bigr).
            \end{align*}
            This lets the model reconstruct pixels from the latent history
    \end{itemize}
\end{frame}

\begin{frame}{Variational Training}
    \begin{itemize}
        \item We introduce an CNN \textbf{encoder} that maps each $\mathbf{x}_t$ to a posterior over $\mathbf{z}_t$:
            \begin{align*}
                q(\mathbf{z}_{0:T}\mid \mathbf{x}_{0:T},\mathbf{a}_{1:T})
                = \prod_{t=0}^T q(\mathbf{z}_t\mid \mathbf{x}_t),
                \quad
                q(\mathbf{z}_0\mid \mathbf{x}_0)=p(\mathbf{z}_0\mid \mathbf{x}_0).
            \end{align*}
            
        \item The \textbf{ELBO} objective is
            \begin{align*}
                \log p(\mathbf{x}_{1:T}\mid \mathbf{x}_0,& \mathbf{a}_{1:T}) 
                \geq \\ \mathbb{E}_{q}\!\Biggl[\sum_{t=1}^T\!\log &p(\mathbf{x}_t\mid \mathbf{z}_{\le t},\mathbf{a}_{\le t})
                \;-\;\mathrm{KL}\bigl(q(\mathbf{z}_t\mid \mathbf{x}_t)\,\|\,p(\mathbf{z}_t\mid \mathbf{z}_{<t},\mathbf{a}_{\le t})\bigr)\Biggr].
            \end{align*}
            
        \item All $\mathbf{z}_t$ samples and PSSM computations run in parallel during training
    \end{itemize}
\end{frame}

\begin{frame}{Training Algorithm}
    \begin{algorithm}[H]
        \caption{S4WM Training}
        \DontPrintSemicolon
        \KwIn{$(\mathbf{x}_0, \mathbf{a}_1, \mathbf{x}_1, \ldots, \mathbf{a}_T, \mathbf{x}_T)$}
        \BlankLine
        \LineComment{Obtain posterior latents}\\
        \For{time step $t = 0, \ldots, T$ \textbf{parallel}}{
            $\mathbf{z}_t \sim q(\mathbf{z}_t|\mathbf{x}_t) = \text{Encoder}(\mathbf{x}_t)$
        }
        \BlankLine
        \LineComment{Prepare inputs to S4 blocks}\\
        \For{time step $t = 1, \ldots, T$ \textbf{parallel}}{
            $\mathbf{g}_t = \text{MLP}([\mathbf{z}_{t-1}; \mathbf{a}_t])$
        }
        \BlankLine
        \LineComment{Encode history by S4 blocks}\\
        $\mathbf{h}_{1:T}, \mathbf{s}_T = \text{S4Blocks}(\mathbf{g}_{1:T}, \mathbf{s}_0)$
        \BlankLine  
        \LineComment{Compute prior and decode posterior latents}\\
        \For{time step $t = 1, \ldots, T$ \textbf{parallel}}{
            $p(\mathbf{z}_t|\mathbf{z}_{<t}, \mathbf{a}_{\leq t}) = \text{MLP}(\mathbf{h}_t)$\;
            $\hat{\mathbf{x}}_t = \text{Decoder}([\mathbf{h}_t; \mathbf{z}_t])$
        }
        \BlankLine
        Compute objective by ELBO Equation
    \end{algorithm}
\end{frame}

\begin{frame}{Imagination Algorithm}
    \begin{algorithm}[H]
        \caption{S4WM Imagination}
        \DontPrintSemicolon
        \KwIn{context $(\mathbf{x}_{0:C}, \mathbf{a}_{1:C})$, query $\mathbf{a}_{C+1:T}$}
        \BlankLine
        \LineComment{Encode context}\\
        \For{context step $t = 0, \ldots, C$ \textbf{parallel}}{
            $\mathbf{z}_t \sim q(\mathbf{z}_t|\mathbf{x}_t) = \text{Encoder}(\mathbf{x}_t)$\;
            $\mathbf{g}_{t+1} = \text{MLP}([\mathbf{z}_t; \mathbf{a}_{t+1}])$
        }
        $\mathbf{h}_{1:C+1}, \mathbf{s}_{C+1} = \text{S4Blocks}(\mathbf{g}_{1:C+1}, \mathbf{s}_0)$
        \BlankLine
        \LineComment{Imagine in latent space}\\
        $\mathbf{z}_{C+1} \sim p(\mathbf{z}_{C+1}|\mathbf{z}_{0:C}, \mathbf{a}_{1:C+1}) = \text{MLP}(\mathbf{h}_{C+1})$\;
        \For{query step $t = C + 2, \ldots, T$}{
            $\mathbf{g}_t = \text{MLP}([\mathbf{z}_{t-1}; \mathbf{a}_t])$\;
            $\mathbf{h}_t, \mathbf{s}_t = \text{S4Blocks}(\mathbf{g}_t, \mathbf{s}_{t-1})$\;
            $\mathbf{z}_t \sim p(\mathbf{z}_t|\mathbf{z}_{<t}, \mathbf{a}_{\leq t}) = \text{MLP}(\mathbf{h}_t)$
        }
        \BlankLine
        \LineComment{Decode imagined latents}\\
        \For{query step $t = C + 1, \ldots, T$ \textbf{parallel}}{
            $\hat{\mathbf{x}}_t = \text{Decoder}([\mathbf{h}_t; \mathbf{z}_t])$
        }
    \end{algorithm}
\end{frame}

\begin{frame}{Environments for Evaluating World Model Memory Capabilities}
    \begin{itemize}
        \item \textbf{Evaluation Focus:} Memory capabilities in world models
            \begin{itemize}
                \item Long-term imagination
                \item Context-dependent recall
                \item Reward prediction
                \item Memory-based reasoning
            \end{itemize}
            
        \item \textbf{Environment Design:}
            \begin{itemize}
                \item 3D Memory Maze and 2D MiniGrid environments with partial observability
                \item Each environment targets specific memory capability
                \item Deterministic environments with moderate visual complexity
            \end{itemize}
            
        \item \textbf{Evaluation Protocol:}
            \begin{itemize}
                \item World model observes context phase
                \item Evaluated on imagination given query phase actions
                \item Mean squared error (MSE) as primary metric
                \item Evaluation on unseen episodes from same policy distribution
            \end{itemize}
            
        \item \textbf{Advantages over Prior Work:}
            \begin{itemize}
                \item Provides deeper insights than final agent performance
                \item Isolates world model capabilities from policy learning
                \item Enables focused assessment of specific memory aspects
                \item Paves way for improved model-based agents with better memory
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{World Model Baselines and Performance Comparison}
    \begin{itemize}
        \item \textbf{Baseline Models:}
            \begin{itemize}
                \item \textbf{RSSM-TBTT:} RNN-based world model with truncated backpropagation
                \item \textbf{TSSM-XL:} Transformer-based model using Transformer-XL for longer sequences
                \item \textbf{S4WM:} Structured State Space Model-based world model
            \end{itemize}
            
        \item \textbf{Computational Efficiency:}
            \begin{itemize}
                \item \textbf{Training Speed:} S4WM and TSSM-XL train faster due to parallel computation
                \item \textbf{Memory Usage:} RSSM-TBTT is most memory-efficient during training
                \item \textbf{Imagination Throughput:} RSSM-TBTT achieves $\sim 10 \times$ faster inference
            \end{itemize}
    \end{itemize}

    \begin{figure}[t]
        \centering
        \includegraphics[width=0.8\textwidth]{figs/model_benchmarks.pdf}
        \caption{Comparison of speed and memory usage during training and imagination. S4WM is the fastest to train, while RSSM-TBTT is the most memory-efficient during training and has the highest throughput during imagination.}
        \label{fig:train_benchmark}
    \end{figure}
\end{frame}

\begin{frame}{Long-Term Imagination}
    \begin{table}[t]
        \label{tab:revisit}
        \vskip 9pt
        \centering
        \begin{adjustbox}{max width=0.8\textwidth}
        \begin{tabular}{lcccccc}
          \toprule
          \multirow{2}{*}{}   & \multicolumn{2}{c}{Two Rooms ($301 \mid 200$)} & \multicolumn{2}{c}{Four Rooms ($501 \mid 500$)}    & \multicolumn{2}{c}{Ten Rooms ($1101 \mid 900$)} \\
          \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
                  & \makecell{Recon. \\ MSE ($\downarrow$)} & \makecell{Gen. \\ MSE ($\downarrow$)} & \makecell{Recon. \\ MSE ($\downarrow$)} & \makecell{Gen. \\ MSE ($\downarrow$)} & \makecell{Recon. \\ MSE ($\downarrow$)} & \makecell{Gen. \\ MSE ($\downarrow$)} \\
          \midrule
          RSSM-TBTT   & $\mathbf{1.7}$ & $62.2$          & $\mathbf{1.5}$ & $219.4$         & $\mathbf{1.5}$ & $323.1$          \\
          TSSM-XL     & $2.5$          & $62.9$          & $2.4$          & $224.4$         & $2.6$          & $360.4$          \\
          S4WM        & $1.8$          & $\mathbf{27.3}$ & $1.7$          & $\mathbf{44.0}$ & $1.8$          & $\mathbf{224.4}$ \\
          \bottomrule
        \end{tabular}
    \end{adjustbox}
    \caption{Long-term imagination evaluation. Format: (context | query steps). All models show good reconstruction, but S4WM excels at generation up to $500$ steps. Ten Rooms remains challenging for all models.}
      \end{table}

      \begin{figure}[t]
        \centering
        \includegraphics[width=0.8\textwidth]{figs/revisit_gen.pdf}
        \caption{Long-term imagination in Four Rooms. RSSM-TBTT and TSSM-XL show significant errors in walls, objects, and positions, while S4WM generates more accurately with only minor position errors.}
        \label{fig:revisit_gen}
    \end{figure}
\end{frame}

\begin{frame}
\frametitle{Context-Dependent Recall}
    \begin{itemize}
        \item \textbf{Teleport Experiment:} Agent observes initial context, then is teleported to random point in history and must recall subsequent events using the same action sequence
        
        \item \textbf{Evaluates:} Models' ability to access specific memories from arbitrary points in history
    \end{itemize}

    \begin{figure}[t]
        \centering
        \includegraphics[width=0.8\textwidth]{figs/teleport.pdf}
        \caption{Context-dependent recall in teleport environments (format: context | query steps). TSSM-XL excels with short contexts, requiring no additional observations, while S4WM performs best with longer context phases.}
        \label{fig:teleport}
    \end{figure}
\end{frame}

\begin{frame}{Reward Prediction}
    \begin{itemize}
        \item To facilitate policy learning within imagination, world models need to accurately predict the rewards
        
        \item We evaluate reward prediction accuracy over long time horizons using the visually simpler 2D MiniGrid environment
        
        \item \textbf{Distracting Memory environment:}
        \begin{itemize}
            \item More challenging than original MiniGird Memory environment
            \item Distractors of random colors placed in hallway
            \item Reward of $1$ given if square reached matches color of square in left room
            \item Model must ignore distractors while tracking agent's position
        \end{itemize}
        
        \item \textbf{Results:}
        \begin{itemize}
            \item Only S4WM accurately predicts rewards within imagination
            \item TSSM-XL succeeds with full sequence but fails in imagination
            \item RSSM-TBTT completely fails (close to random guessing)
            \item Failures mainly due to inability to track agent's position
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}{Reward Prediction (cont.)}
    \begin{table}[t]
      \caption{Reward prediction accuracy in the Distracting Memory environments. Each environment is labeled with (context steps | query steps). S4WM succeeds in all environments. TSSM-XL has limited success when observing the full sequence, but fails to predict rewards within imagination. RSSM-TBTT completely fails.}
      \label{tab:reward}
      \vskip 9pt
      \centering
      \begin{adjustbox}{max width=0.9\textwidth}
      \begin{tabular}{lcccccc}
        \toprule
        \multirow{2}{*}{}   & \multicolumn{2}{c}{$\text{Width} = 100$ ($199 \mid 51$)} & \multicolumn{2}{c}{$\text{Width} = 200$ ($399 \mid 101$)}    & \multicolumn{2}{c}{$\text{Width} = 400$ ($799 \mid 201$)} \\
        \cmidrule(lr){2-3} \cmidrule(lr){4-5} \cmidrule(lr){6-7}
                & \makecell{Inference \\ Accuracy ($\uparrow$)} & \makecell{Imagination \\ Accuracy ($\uparrow$)} & \makecell{Inference \\ Accuracy ($\uparrow$)} & \makecell{Imagination \\ Accuracy ($\uparrow$)} & \makecell{Inference \\ Accuracy ($\uparrow$)} & \makecell{Imagination \\ Accuracy ($\uparrow$)} \\
        \midrule
        RSSM-TBTT   & $47.9\%$           & $49.6\%$           & $48.7\%$           & $48.4\%$           & $50.4\%$           & $52.2\%$ \\
        TSSM-XL     & $\mathbf{100.0\%}$ & $51.2\%$           & $99.9\%$           & $51.3\%$           & $50.4\%$           & $51.0\%$ \\
        S4WM        & $\mathbf{100.0\%}$ & $\mathbf{100.0\%}$ & $\mathbf{100.0\%}$ & $\mathbf{100.0\%}$ & $\mathbf{100.0\%}$ & $\mathbf{100.0\%}$ \\
        \bottomrule
      \end{tabular}
      \end{adjustbox}
    \end{table}

    \begin{figure}[t]
        \centering
        \includegraphics[width=0.9\textwidth]{figs/reward_gen.pdf}
        \caption{Imagination in the Distracting Memory environment of width $100$. RSSM-TBTT and TSSM-XL fail to keep track of the agent's position, leading to inaccurate reward prediction within imagination.}
        \label{fig:reward_gen}
    \end{figure}
\end{frame}


\end{document}