\documentclass[9pt]{beamer}
\input{commands}

% Basic packages
\usepackage[utf8]{inputenc}
\usepackage{microtype}
\usepackage{hyperref}
\usepackage{url}
\usepackage{nicefrac}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage[ruled, vlined]{algorithm2e}
\usepackage{sidecap}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}
\usepackage{makecell}
\usepackage[sort]{natbib}

\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=newest}
\usetikzlibrary{arrows,arrows.meta,calc}
\usetikzlibrary{patterns,backgrounds}
\usetikzlibrary{positioning,fit}
\usetikzlibrary{shapes.geometric,shapes.multipart}
\usetikzlibrary{patterns.meta,decorations.pathreplacing,calligraphy}
\usetikzlibrary{tikzmark}
\usetikzlibrary{decorations.pathmorphing}

\AtBeginDocument{\RenewCommandCopy\qty\SI}
\pgfplotsset{compat=newest}
\setbeamertemplate{navigation symbols}{}
\setbeamertemplate{footline}{%
  \hfill\usebeamercolor[fg]{page number in head/foot}%
  \usebeamerfont{page number in head/foot}%
  \insertframenumber\,/\,\inserttotalframenumber\hspace*{1ex}\vskip2pt%
}
\setbeamercolor{page number in head/foot}{fg=gray}
\setbeamerfont{page number in head/foot}{size=\small}
\setbeamerfont{title}{size=\huge}


% Figure reference, lower-case.
\def\figref#1{figure~\ref{#1}}
% Figure reference, capital. For start of sentence
\def\Figref#1{Figure~\ref{#1}}
\def\twofigref#1#2{figures \ref{#1} and \ref{#2}}
\def\quadfigref#1#2#3#4{figures \ref{#1}, \ref{#2}, \ref{#3} and \ref{#4}}
% Section reference, lower-case.
\def\secref#1{section~\ref{#1}}
% Section reference, capital.
\def\Secref#1{Section~\ref{#1}}
% Reference to two sections.
\def\twosecrefs#1#2{sections \ref{#1} and \ref{#2}}
% Reference to three sections.
\def\secrefs#1#2#3{sections \ref{#1}, \ref{#2} and \ref{#3}}
% Reference to an equation, lower-case.
\def\eqref#1{equation~\ref{#1}}
% Reference to an equation, upper case
\def\Eqref#1{Equation~\ref{#1}}
% A raw reference to an equation---avoid using if possible
\def\plaineqref#1{\ref{#1}}
% Reference to a chapter, lower-case.
\def\chapref#1{chapter~\ref{#1}}
% Reference to an equation, upper case.
\def\Chapref#1{Chapter~\ref{#1}}
% Reference to a range of chapters
\def\rangechapref#1#2{chapters\ref{#1}--\ref{#2}}
% Reference to an algorithm, lower-case.
\def\algref#1{algorithm~\ref{#1}}
% Reference to an algorithm, upper case.
\def\Algref#1{Algorithm~\ref{#1}}
\def\twoalgref#1#2{algorithms \ref{#1} and \ref{#2}}
\def\Twoalgref#1#2{Algorithms \ref{#1} and \ref{#2}}
% Reference to a part, lower case
\def\partref#1{part~\ref{#1}}
% Reference to a part, upper case
\def\Partref#1{Part~\ref{#1}}
\def\twopartref#1#2{parts \ref{#1} and \ref{#2}}

\def\ceil#1{\lceil #1 \rceil}
\def\floor#1{\lfloor #1 \rfloor}
\def\1{\bm{1}}
\newcommand{\train}{\mathcal{D}}
\newcommand{\valid}{\mathcal{D_{\mathrm{valid}}}}
\newcommand{\test}{\mathcal{D_{\mathrm{test}}}}

\def\eps{{\epsilon}}


% Random variables
\def\reta{{\textnormal{$\eta$}}}
\def\ra{{\textnormal{a}}}
\def\rb{{\textnormal{b}}}
\def\rc{{\textnormal{c}}}
\def\rd{{\textnormal{d}}}
\def\re{{\textnormal{e}}}
\def\rf{{\textnormal{f}}}
\def\rg{{\textnormal{g}}}
\def\rh{{\textnormal{h}}}
\def\ri{{\textnormal{i}}}
\def\rj{{\textnormal{j}}}
\def\rk{{\textnormal{k}}}
\def\rl{{\textnormal{l}}}
% rm is already a command, just don't name any random variables m
\def\rn{{\textnormal{n}}}
\def\ro{{\textnormal{o}}}
\def\rp{{\textnormal{p}}}
\def\rq{{\textnormal{q}}}
\def\rr{{\textnormal{r}}}
\def\rs{{\textnormal{s}}}
\def\rt{{\textnormal{t}}}
\def\ru{{\textnormal{u}}}
\def\rv{{\textnormal{v}}}
\def\rw{{\textnormal{w}}}
\def\rx{{\textnormal{x}}}
\def\ry{{\textnormal{y}}}
\def\rz{{\textnormal{z}}}

% Random vectors
\def\rvepsilon{{\mathbf{\epsilon}}}
\def\rvtheta{{\mathbf{\theta}}}
\def\rva{{\mathbf{a}}}
\def\rvb{{\mathbf{b}}}
\def\rvc{{\mathbf{c}}}
\def\rvd{{\mathbf{d}}}
\def\rve{{\mathbf{e}}}
\def\rvf{{\mathbf{f}}}
\def\rvg{{\mathbf{g}}}
\def\rvh{{\mathbf{h}}}
\def\rvu{{\mathbf{i}}}
\def\rvj{{\mathbf{j}}}
\def\rvk{{\mathbf{k}}}
\def\rvl{{\mathbf{l}}}
\def\rvm{{\mathbf{m}}}
\def\rvn{{\mathbf{n}}}
\def\rvo{{\mathbf{o}}}
\def\rvp{{\mathbf{p}}}
\def\rvq{{\mathbf{q}}}
\def\rvr{{\mathbf{r}}}
\def\rvs{{\mathbf{s}}}
\def\rvt{{\mathbf{t}}}
\def\rvu{{\mathbf{u}}}
\def\rvv{{\mathbf{v}}}
\def\rvw{{\mathbf{w}}}
\def\rvx{{\mathbf{x}}}
\def\rvy{{\mathbf{y}}}
\def\rvz{{\mathbf{z}}}

% Elements of random vectors
\def\erva{{\textnormal{a}}}
\def\ervb{{\textnormal{b}}}
\def\ervc{{\textnormal{c}}}
\def\ervd{{\textnormal{d}}}
\def\erve{{\textnormal{e}}}
\def\ervf{{\textnormal{f}}}
\def\ervg{{\textnormal{g}}}
\def\ervh{{\textnormal{h}}}
\def\ervi{{\textnormal{i}}}
\def\ervj{{\textnormal{j}}}
\def\ervk{{\textnormal{k}}}
\def\ervl{{\textnormal{l}}}
\def\ervm{{\textnormal{m}}}
\def\ervn{{\textnormal{n}}}
\def\ervo{{\textnormal{o}}}
\def\ervp{{\textnormal{p}}}
\def\ervq{{\textnormal{q}}}
\def\ervr{{\textnormal{r}}}
\def\ervs{{\textnormal{s}}}
\def\ervt{{\textnormal{t}}}
\def\ervu{{\textnormal{u}}}
\def\ervv{{\textnormal{v}}}
\def\ervw{{\textnormal{w}}}
\def\ervx{{\textnormal{x}}}
\def\ervy{{\textnormal{y}}}
\def\ervz{{\textnormal{z}}}

% Random matrices
\def\rmA{{\mathbf{A}}}
\def\rmB{{\mathbf{B}}}
\def\rmC{{\mathbf{C}}}
\def\rmD{{\mathbf{D}}}
\def\rmE{{\mathbf{E}}}
\def\rmF{{\mathbf{F}}}
\def\rmG{{\mathbf{G}}}
\def\rmH{{\mathbf{H}}}
\def\rmI{{\mathbf{I}}}
\def\rmJ{{\mathbf{J}}}
\def\rmK{{\mathbf{K}}}
\def\rmL{{\mathbf{L}}}
\def\rmM{{\mathbf{M}}}
\def\rmN{{\mathbf{N}}}
\def\rmO{{\mathbf{O}}}
\def\rmP{{\mathbf{P}}}
\def\rmQ{{\mathbf{Q}}}
\def\rmR{{\mathbf{R}}}
\def\rmS{{\mathbf{S}}}
\def\rmT{{\mathbf{T}}}
\def\rmU{{\mathbf{U}}}
\def\rmV{{\mathbf{V}}}
\def\rmW{{\mathbf{W}}}
\def\rmX{{\mathbf{X}}}
\def\rmY{{\mathbf{Y}}}
\def\rmZ{{\mathbf{Z}}}

% Elements of random matrices
\def\ermA{{\textnormal{A}}}
\def\ermB{{\textnormal{B}}}
\def\ermC{{\textnormal{C}}}
\def\ermD{{\textnormal{D}}}
\def\ermE{{\textnormal{E}}}
\def\ermF{{\textnormal{F}}}
\def\ermG{{\textnormal{G}}}
\def\ermH{{\textnormal{H}}}
\def\ermI{{\textnormal{I}}}
\def\ermJ{{\textnormal{J}}}
\def\ermK{{\textnormal{K}}}
\def\ermL{{\textnormal{L}}}
\def\ermM{{\textnormal{M}}}
\def\ermN{{\textnormal{N}}}
\def\ermO{{\textnormal{O}}}
\def\ermP{{\textnormal{P}}}
\def\ermQ{{\textnormal{Q}}}
\def\ermR{{\textnormal{R}}}
\def\ermS{{\textnormal{S}}}
\def\ermT{{\textnormal{T}}}
\def\ermU{{\textnormal{U}}}
\def\ermV{{\textnormal{V}}}
\def\ermW{{\textnormal{W}}}
\def\ermX{{\textnormal{X}}}
\def\ermY{{\textnormal{Y}}}
\def\ermZ{{\textnormal{Z}}}

% Vectors
\def\vzero{{\bm{0}}}
\def\vone{{\bm{1}}}
\def\vmu{{\bm{\mu}}}
\def\vtheta{{\bm{\theta}}}
\def\va{{\bm{a}}}
\def\vb{{\bm{b}}}
\def\vc{{\bm{c}}}
\def\vd{{\bm{d}}}
\def\ve{{\bm{e}}}
\def\vf{{\bm{f}}}
\def\vg{{\bm{g}}}
\def\vh{{\bm{h}}}
\def\vi{{\bm{i}}}
\def\vj{{\bm{j}}}
\def\vk{{\bm{k}}}
\def\vl{{\bm{l}}}
\def\vm{{\bm{m}}}
\def\vn{{\bm{n}}}
\def\vo{{\bm{o}}}
\def\vp{{\bm{p}}}
\def\vq{{\bm{q}}}
\def\vr{{\bm{r}}}
\def\vs{{\bm{s}}}
\def\vt{{\bm{t}}}
\def\vu{{\bm{u}}}
\def\vv{{\bm{v}}}
\def\vw{{\bm{w}}}
\def\vx{{\bm{x}}}
\def\vy{{\bm{y}}}
\def\vz{{\bm{z}}}

% Elements of vectors
\def\evalpha{{\alpha}}
\def\evbeta{{\beta}}
\def\evepsilon{{\epsilon}}
\def\evlambda{{\lambda}}
\def\evomega{{\omega}}
\def\evmu{{\mu}}
\def\evpsi{{\psi}}
\def\evsigma{{\sigma}}
\def\evtheta{{\theta}}
\def\eva{{a}}
\def\evb{{b}}
\def\evc{{c}}
\def\evd{{d}}
\def\eve{{e}}
\def\evf{{f}}
\def\evg{{g}}
\def\evh{{h}}
\def\evi{{i}}
\def\evj{{j}}
\def\evk{{k}}
\def\evl{{l}}
\def\evm{{m}}
\def\evn{{n}}
\def\evo{{o}}
\def\evp{{p}}
\def\evq{{q}}
\def\evr{{r}}
\def\evs{{s}}
\def\evt{{t}}
\def\evu{{u}}
\def\evv{{v}}
\def\evw{{w}}
\def\evx{{x}}
\def\evy{{y}}
\def\evz{{z}}

% Matrix
\def\mA{{\bm{A}}}
\def\mB{{\bm{B}}}
\def\mC{{\bm{C}}}
\def\mD{{\bm{D}}}
\def\mE{{\bm{E}}}
\def\mF{{\bm{F}}}
\def\mG{{\bm{G}}}
\def\mH{{\bm{H}}}
\def\mI{{\bm{I}}}
\def\mJ{{\bm{J}}}
\def\mK{{\bm{K}}}
\def\mL{{\bm{L}}}
\def\mM{{\bm{M}}}
\def\mN{{\bm{N}}}
\def\mO{{\bm{O}}}
\def\mP{{\bm{P}}}
\def\mQ{{\bm{Q}}}
\def\mR{{\bm{R}}}
\def\mS{{\bm{S}}}
\def\mT{{\bm{T}}}
\def\mU{{\bm{U}}}
\def\mV{{\bm{V}}}
\def\mW{{\bm{W}}}
\def\mX{{\bm{X}}}
\def\mY{{\bm{Y}}}
\def\mZ{{\bm{Z}}}
\def\mBeta{{\bm{\beta}}}
\def\mPhi{{\bm{\Phi}}}
\def\mLambda{{\bm{\Lambda}}}
\def\mSigma{{\bm{\Sigma}}}

% Tensor
\DeclareMathAlphabet{\mathsfit}{\encodingdefault}{\sfdefault}{m}{sl}
\SetMathAlphabet{\mathsfit}{bold}{\encodingdefault}{\sfdefault}{bx}{n}
\newcommand{\tens}[1]{\bm{\mathsfit{#1}}}
\def\tA{{\tens{A}}}
\def\tB{{\tens{B}}}
\def\tC{{\tens{C}}}
\def\tD{{\tens{D}}}
\def\tE{{\tens{E}}}
\def\tF{{\tens{F}}}
\def\tG{{\tens{G}}}
\def\tH{{\tens{H}}}
\def\tI{{\tens{I}}}
\def\tJ{{\tens{J}}}
\def\tK{{\tens{K}}}
\def\tL{{\tens{L}}}
\def\tM{{\tens{M}}}
\def\tN{{\tens{N}}}
\def\tO{{\tens{O}}}
\def\tP{{\tens{P}}}
\def\tQ{{\tens{Q}}}
\def\tR{{\tens{R}}}
\def\tS{{\tens{S}}}
\def\tT{{\tens{T}}}
\def\tU{{\tens{U}}}
\def\tV{{\tens{V}}}
\def\tW{{\tens{W}}}
\def\tX{{\tens{X}}}
\def\tY{{\tens{Y}}}
\def\tZ{{\tens{Z}}}


% Graph
\def\gA{{\mathcal{A}}}
\def\gB{{\mathcal{B}}}
\def\gC{{\mathcal{C}}}
\def\gD{{\mathcal{D}}}
\def\gE{{\mathcal{E}}}
\def\gF{{\mathcal{F}}}
\def\gG{{\mathcal{G}}}
\def\gH{{\mathcal{H}}}
\def\gI{{\mathcal{I}}}
\def\gJ{{\mathcal{J}}}
\def\gK{{\mathcal{K}}}
\def\gL{{\mathcal{L}}}
\def\gM{{\mathcal{M}}}
\def\gN{{\mathcal{N}}}
\def\gO{{\mathcal{O}}}
\def\gP{{\mathcal{P}}}
\def\gQ{{\mathcal{Q}}}
\def\gR{{\mathcal{R}}}
\def\gS{{\mathcal{S}}}
\def\gT{{\mathcal{T}}}
\def\gU{{\mathcal{U}}}
\def\gV{{\mathcal{V}}}
\def\gW{{\mathcal{W}}}
\def\gX{{\mathcal{X}}}
\def\gY{{\mathcal{Y}}}
\def\gZ{{\mathcal{Z}}}

% Sets
\def\sA{{\mathbb{A}}}
\def\sB{{\mathbb{B}}}
\def\sC{{\mathbb{C}}}
\def\sD{{\mathbb{D}}}
% Don't use a set called E, because this would be the same as our symbol
% for expectation.
\def\sF{{\mathbb{F}}}
\def\sG{{\mathbb{G}}}
\def\sH{{\mathbb{H}}}
\def\sI{{\mathbb{I}}}
\def\sJ{{\mathbb{J}}}
\def\sK{{\mathbb{K}}}
\def\sL{{\mathbb{L}}}
\def\sM{{\mathbb{M}}}
\def\sN{{\mathbb{N}}}
\def\sO{{\mathbb{O}}}
\def\sP{{\mathbb{P}}}
\def\sQ{{\mathbb{Q}}}
\def\sR{{\mathbb{R}}}
\def\sS{{\mathbb{S}}}
\def\sT{{\mathbb{T}}}
\def\sU{{\mathbb{U}}}
\def\sV{{\mathbb{V}}}
\def\sW{{\mathbb{W}}}
\def\sX{{\mathbb{X}}}
\def\sY{{\mathbb{Y}}}
\def\sZ{{\mathbb{Z}}}

% Entries of a matrix
\def\emLambda{{\Lambda}}
\def\emA{{A}}
\def\emB{{B}}
\def\emC{{C}}
\def\emD{{D}}
\def\emE{{E}}
\def\emF{{F}}
\def\emG{{G}}
\def\emH{{H}}
\def\emI{{I}}
\def\emJ{{J}}
\def\emK{{K}}
\def\emL{{L}}
\def\emM{{M}}
\def\emN{{N}}
\def\emO{{O}}
\def\emP{{P}}
\def\emQ{{Q}}
\def\emR{{R}}
\def\emS{{S}}
\def\emT{{T}}
\def\emU{{U}}
\def\emV{{V}}
\def\emW{{W}}
\def\emX{{X}}
\def\emY{{Y}}
\def\emZ{{Z}}
\def\emSigma{{\Sigma}}

% entries of a tensor
% Same font as tensor, without \bm wrapper
\newcommand{\etens}[1]{\mathsfit{#1}}
\def\etLambda{{\etens{\Lambda}}}
\def\etA{{\etens{A}}}
\def\etB{{\etens{B}}}
\def\etC{{\etens{C}}}
\def\etD{{\etens{D}}}
\def\etE{{\etens{E}}}
\def\etF{{\etens{F}}}
\def\etG{{\etens{G}}}
\def\etH{{\etens{H}}}
\def\etI{{\etens{I}}}
\def\etJ{{\etens{J}}}
\def\etK{{\etens{K}}}
\def\etL{{\etens{L}}}
\def\etM{{\etens{M}}}
\def\etN{{\etens{N}}}
\def\etO{{\etens{O}}}
\def\etP{{\etens{P}}}
\def\etQ{{\etens{Q}}}
\def\etR{{\etens{R}}}
\def\etS{{\etens{S}}}
\def\etT{{\etens{T}}}
\def\etU{{\etens{U}}}
\def\etV{{\etens{V}}}
\def\etW{{\etens{W}}}
\def\etX{{\etens{X}}}
\def\etY{{\etens{Y}}}
\def\etZ{{\etens{Z}}}

% The true underlying data generating distribution
\newcommand{\pdata}{p_{\rm{data}}}
% The empirical distribution defined by the training set
\newcommand{\ptrain}{\hat{p}_{\rm{data}}}
\newcommand{\Ptrain}{\hat{P}_{\rm{data}}}
% The model distribution
\newcommand{\pmodel}{p_{\rm{model}}}
\newcommand{\Pmodel}{P_{\rm{model}}}
\newcommand{\ptildemodel}{\tilde{p}_{\rm{model}}}
% Stochastic autoencoder distributions
\newcommand{\pencode}{p_{\rm{encoder}}}
\newcommand{\pdecode}{p_{\rm{decoder}}}
\newcommand{\precons}{p_{\rm{reconstruct}}}

\newcommand{\laplace}{\mathrm{Laplace}} % Laplace distribution

\newcommand{\E}{\mathbb{E}}
\newcommand{\Ls}{\mathcal{L}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\emp}{\tilde{p}}
\newcommand{\lr}{\alpha}
\newcommand{\reg}{\lambda}
\newcommand{\rect}{\mathrm{rectifier}}
\newcommand{\softmax}{\mathrm{softmax}}
\newcommand{\sigmoid}{\sigma}
\newcommand{\softplus}{\zeta}
\newcommand{\KL}{D_{\mathrm{KL}}}
\newcommand{\Var}{\mathrm{Var}}
\newcommand{\standarderror}{\mathrm{SE}}
\newcommand{\Cov}{\mathrm{Cov}}
% Wolfram Mathworld says $L^2$ is for function spaces and $\ell^2$ is for vectors
% But then they seem to use $L^2$ for vectors throughout the site, and so does
% wikipedia.
\newcommand{\normlzero}{L^0}
\newcommand{\normlone}{L^1}
\newcommand{\normltwo}{L^2}
\newcommand{\normlp}{L^p}
\newcommand{\normmax}{L^\infty}

\newcommand{\parents}{Pa} % See usage in notation.tex. Chosen to match Daphne's book.

\let\ab\allowbreak

\title{Drama: Mamba-Enabled Model-Based Reinforcement Learning Is Sample and Parameter Efficient}
\date{April 16, 2025}
\begin{document}

\begin{frame}
    \titlepage
\end{frame}

\begin{frame}
    \frametitle{Reference}

    \bibliographystyle{plainnat}
    \bibliography{references}
\end{frame}

\begin{frame}
    \frametitle{Drama \citep{wang2025dramamambaenabledmodelbasedreinforcement} Abstract}
    
    \textbf{Challenges in Current World Models:}
    \begin{itemize}
        \item RNNs: Struggle with vanishing gradients and long-term dependencies
        \item Transformers: Suffer from $O(n^2)$ memory and computational complexity
    \end{itemize}
    
    \textbf{Their Approach - Drama:}
    \begin{itemize}
        \item State space model (SSM)-based world model leveraging Mamba
        \item Achieves $O(n)$ memory and computational complexity
        \item Effectively captures long-term dependencies
        \item Novel sampling method to mitigate suboptimality from incorrect world models
    \end{itemize}
    
    \textbf{Results:}
    \begin{itemize}
        \item Competitive normalized score on \textit{Atari100k} benchmark
        \item Only 7 million parameters in world model
        \item Trainable on standard laptops
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Problem Formulation: POMDP}
    
    \textbf{POMDP Environment:}
    \begin{itemize}
        \item Agent observes image $\tO_t \in \sO$ instead of true state $\evs_t \in \sS$
        \item Observation probability: $p(\tO_t|\evs_t)$
        \item Discrete action space: $\eva_t \in \sA = \{0, 1, \dots, n \}$
        \item Transition dynamics: $p(\evs_{t+1},\evr_t|\evs_t, \eva_t)$
    \end{itemize}
    
    \textbf{Agent:}
    \begin{itemize}
        \item Policy $\pi(\tO_t;\vtheta): \sO \rightarrow \sA$
        \item Objective: Maximize $\E \sum_t \gamma^t \evr_t$
    \end{itemize}
    
    \textbf{Model-Based Approach:}
    \begin{itemize}
        \item Learn world model $f(\tO_t, a_t; \omega)$ from experiences
        \item World model components: VAE, sequence model, reward/termination predictors
        \item "Imagination" process: Generate synthetic experiences for policy improvement
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Drama Architecture}
    
    \begin{figure}
        \centering
        \includegraphics[width=\textwidth]{figures/drama_graph.pdf}
        \caption{Drama architecture combining Mamba-based SSM world model with model-based RL}
    \end{figure}
\end{frame}


\begin{frame}
    \frametitle{State Space Models (SSMs) - Basic Framework}
    
    \textbf{Core Equations:}
    \begin{align*}
        \mH_t &= \mA\,\mH_{t-1} + \mB\,\evx_t\\
        \evy_t &= \mC^\intercal\,\mH_t
    \end{align*}
    
    \textbf{Key Components:}
    \begin{itemize}
        \item $\mH_t \in \sR^n$: Hidden state summarizing input history
        \item $\evx_t$: Input at time $t$
        \item $\evy_t$: Output at time $t$
        \item $\mA$: State transition matrix
        \item $\mB$, $\mC$: Input encoding and state decoding matrices
    \end{itemize}
    
    \textbf{Advantages:}
    \begin{itemize}
        \item Fixed-size hidden state regardless of sequence length
        \item $O(n)$ memory and computational complexity
        \item Strong theoretical foundation in control theory
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Efficient SSM Structures}
    
    \textbf{Diagonal Structure:}
    \begin{itemize}
        \item Restrict $\mA$ to be diagonal for computational efficiency
        \item Each dimension of hidden state updated independently
    \end{itemize}
    
    \textbf{Time-Varying Matrices (Selective SSMs):}
    \begin{itemize}
        \item Extend matrices to be time-dependent:
        \begin{align*}
            \tilde{\mA} &\in \sR^{(T,N,N)}\\
            \mB &\in \sR^{(T,N)}\\
            \mC &\in \sR^{(T,N)}
        \end{align*}
        \item Allows model to adapt dynamics over sequence
        \item Enables capturing richer temporal patterns
    \end{itemize}
    
    \textbf{Structured State Space Duality (SSD):}
    \begin{itemize}
        \item Further constrains $\mA$ as scalar multiple of identity matrix
        \item Simplifies model mathematically but limits expressiveness
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Mamba-2: Enhanced Expressiveness}
    
    \textbf{Multi-Head Technique:}
    \begin{itemize}
        \item Treats each input channel as independent sequence
        \item Multiple "heads" learn different aspects of sequence dynamics
        \item Mitigates expressiveness limitations of simplified $\mA$ matrix
    \end{itemize}
    
    \textbf{Matrix Multiplication Reformulation:}
    \begin{align*}
        \evy = \operatorname{SSM}(\evx;\,\tilde{\mA},\mB,\mC) = \mathbf{M}\,\evx
    \end{align*}
    
    \textbf{Transformation Matrix Entries:}
    \begin{align*}
        \mathbf{M}_{j,i} = 
        \begin{cases}
            \mC_j^\intercal\,\mA_{j:i}\,\mB_i & \text{if } j \geq i, \\
            0 & \text{if } j < i,
        \end{cases}
    \end{align*}
    where $\mA_{j:i} = \mA_j \mA_{j-1} \dots \mA_{i+1}$
    
    \textbf{Benefits:}
    \begin{itemize}
        \item 2-8Ã— faster than original Mamba
        \item Highly GPU-efficient
        \item Maintains $O(n)$ scaling with sequence length
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Connection to Causal Self-Attention}
    
    \textbf{Semi-Separable Matrix Decomposition:}
    \begin{align*}
        \mathbf{M} = \mathbf{L} \circ (\mC\,\mB^\intercal)
    \end{align*}
    
    \textbf{Lower-Triangular Matrix Structure:}
    \begin{align*}
        \mathbf{L} =
        \begin{bmatrix}
            1 &  &  &  \\
            a_1 & 1 &  &  \\
            a_2a_1 & a_2 & 1 &  \\
            \vdots & \vdots & \ddots & \ddots \\
            a_{T-1}\dots a_1 & a_{T-1}\dots a_2 & \dots & a_{T-1} & 1 \\
        \end{bmatrix}
    \end{align*}
    where each $a_t \in [0, 1]$ is input-dependent
    
    \textbf{Relationship to Attention:}
    \begin{itemize}
        \item $\mathbf{L}$ enforces causality similar to attention masks
        \item Replaces softmax normalization in traditional attention
        \item Creates direct link between SSMs and causal linear attention
        \item More efficient pathway to model dependencies
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Summary of SSM Advantages}
    
    \textbf{Control-Theoretic Foundation:}
    \begin{itemize}
        \item Leverages established control theory principles
        \item Hidden state captures evolution of input history
    \end{itemize}
    
    \textbf{Computational Efficiency:}
    \begin{itemize}
        \item Linear $O(n)$ complexity in sequence length
        \item Diagonal and time-varying structures optimize computation
        \item Matrix multiplication formulation enables GPU acceleration
    \end{itemize}
    
    \textbf{Modeling Capabilities:}
    \begin{itemize}
        \item Effectively captures long-range dependencies
        \item Multi-head approach enhances expressiveness
        \item Connection to attention mechanisms without quadratic complexity
    \end{itemize}
    
    \textbf{Practical Benefits:}
    \begin{itemize}
        \item Enables processing of longer sequences
        \item Reduced memory requirements
        \item Faster training and inference
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Latent Space Sequence Modeling with Mamba-2}
    
    \textbf{Key Components:}
    \begin{itemize}
        \item \textbf{Latent Variable} $\vz_t$: Lower-dimensional encoding of observations
        \item \textbf{Deterministic State} $\vd_t$: Distinct from hidden states used by SSMs to track dynamics
        \item \textbf{Action Integration}: Concatenates latent $\vz_t$ with action $a_t$ and projects through a fully connected layer
    \end{itemize}
    
    \textbf{Sequence Construction:}
    \begin{align*}
        &\text{Sequence model:} \hspace{18mm} \vd_t = f(\vz_{t-l:t}, a_{t-l:t}; \omega) \\
        &\text{Latent variable predictor:} \hspace{6mm} \hat{\vz}_{t+1} \sim p(\hat{\vz}_{t+1}|\vd_t; \omega)
    \end{align*}
\end{frame}

\begin{frame}
    \frametitle{Latent Space Sequence Modeling with Mamba-2 (cont.)}
    
    \textbf{Implementation Features:}
    \begin{itemize}
        \item Processes batches $\tO \in [0, 255]^{(b, l, h, w, c)}$ from experience buffer $\mathcal{E}$
        \item Encodes to latent representations $\tZ \in \mathbb{R}^{(b, l, d)}$
        \item Eliminates sequential dependencies: $\vz_{t+1}$ depends solely on observation $\tO_{t+1}$
        \item Linear scaling with sequence length $O(l)$ rather than quadratic
    \end{itemize}
    
    \textbf{Processing Pipeline:}
    \begin{itemize}
        \item Input tensor $\tX_{b, :l, d}$ processed into hidden states $\tH \in \mathbb{R}^{(b, l-1, n)}$ with fixed dimension $n$
        \item Hidden states remapped to deterministic state sequence $\tD_{b, :l, d}$ using time-varying parameters
        \item Multi-headed approach: latent dimension $d$ split into $\frac{d}{p}$ independently processed heads
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Mamba-2 Architecture for Sequence Modeling}
    
    \textbf{Structured Transformation Matrix:}
    \begin{itemize}
        \item Semiseparable lower triangular matrix ensures causality
        \item Decomposed into $q \times q$ specialized blocks for:
            \begin{itemize}
                \item Short-range causal attention
                \item Hidden state transformations
            \end{itemize}
        \item Leverages matrix multiplication for efficient computation
    \end{itemize}
    
    \textbf{Advantages:}
    \begin{itemize}
        \item Efficiently captures temporal dynamics in latent space
        \item Hidden states operate in fixed dimension (unlike attention where state scales with sequence length)
        \item Combines benefits of state-space models with attention-like mechanisms
        \item Achieves linear computational complexity in sequence length $l$
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Behaviour Policy Learning in Imagination}
    
    \textbf{Imagination Process:}
    \begin{itemize}
        \item Autoregressive simulation driven by Mamba sequence model
        \item Samples $b_{img}$ trajectories (length $l_{img}$) from replay buffer
        \item Extends each trajectory with $h$ additional simulated steps
        \item Automatic state reset at episode boundaries (no manual intervention)
    \end{itemize}
    
    \textbf{Key Advantages:}
    \begin{itemize}
        \item Decouples inference parameter updates from sequence length
        \item Significantly accelerates imagination process
        \item Rich state representation: $\hat{\vz}_t$ (predictions) + $\vd_t$ (history)
        \item Actor-critic architecture with specialized normalization techniques
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Dynamic Frequency-Based Sampling (DFS)}
    
    \textbf{Motivation:}
    \begin{itemize}
        \item Early in training, world model has significant inaccuracies
        \item Unreliable predictions lead to reward underestimation and poor exploration
        \item Need to ensure behavior policy uses transitions the world model understands well
    \end{itemize}
    
    \textbf{Dual Tracking System:}
    \begin{itemize}
        \item World model tracking: $\vv = (\evv_1, \evv_2, \ldots, \evv_{|\mathcal{E}|})$
            \begin{itemize}
                \item $\evv_i$ counts how often transition $i$ sampled for world model training
            \end{itemize}
        \item Behavior policy tracking: $\vb = (\evb_1, \evb_2, \ldots, \evb_{|\mathcal{E}|})$
            \begin{itemize}
                \item $\evb_i$ counts how often transition $i$ used for actor-critic learning
            \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{DFS Implementation Details}

    \textbf{World Model Sampling Probabilities:}
    \begin{align*}
        (p_1, p_2, \ldots, p_{|\mathcal{E}|}) &= \texttt{softmax}(-\vv)
    \end{align*}
    
    \textbf{Behavior Policy Sampling Probabilities:}
    \begin{align*}
        (q_1, q_2, \ldots, q_{|\mathcal{E}|}) &= \texttt{softmax}(f(\vv,\vb)), \\ \text{ where } f(\vv,\vb) &= \vv - \vb - \max(0, \vv - \vb)
    \end{align*}
    
    \textbf{Piecewise Behavior:}
    \begin{itemize}
        \item When $\evv_i \geq \evb_i$: $f(\evv_i,\evb_i) = 0$
            \begin{itemize}
                \item World model sufficiently trained on this transition
                \item Reliable for imagination process
            \end{itemize}
        \item When $\evv_i < \evb_i$: $f(\evv_i,\evb_i) = \evv_i - \evb_i < 0$
            \begin{itemize}
                \item Lower probability assigned via softmax
                \item Avoids using transitions with unreliable world model predictions
            \end{itemize}
    \end{itemize}
    
    \textbf{Benefits:}
    \begin{itemize}
        \item Ensures imagination based on reliable world model predictions
        \item Prevents overfitting to poorly learned experiences
        \item Dynamically adapts as training progresses
        \item Balances exploration and exploitation in model-based RL
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{Atari100k Benchmark Results}
    
    \begin{table}[!ht] 
        \centering
        \renewcommand{\arraystretch}{1.3} % Adjust the row height
        \resizebox{\textwidth}{!}{
        \begin{tabular}{lllrrrrrrrr}
        \hline
           ~ & Random & Human & PPO & SimPLe & SPR & TWM & IRIS & STROM & DreamerV3 & DramaXS \\ \hline
            Alien & 228 & 7128 & 276 & 617 & 842 & 675 & 420 & 984 & \textbf{1118} & 820 \\ 
            Amidar & 6 & 1720 & 26 & 74 & 180 & 122 & 143 & \textbf{205} & 97 & 131 \\ 
            Assault & 222 & 742 & 327 & 527 & 566 & 683 & \textbf{1524} & 801 & 683 & 539 \\ 
            Asterix & 210 & 8503 & 292 & 1128 & 962 & 1117 & 854 & 1028 & 1062 & \textbf{1632} \\ 
            BankHeist & 14 & 753 & 14 & 34 & 345 & 467 & 53 & \textbf{641} & 398 & 137 \\ 
            BattleZone & 2360 & 37188 & 2233 & 4031 & 14834 & 5068 & 13074 & 13540 & \textbf{20300} & 10860 \\ 
            Boxing & 0 & 12 & 3 & 8 & 36 & 78 & 70 & 80 & \textbf{82} & 78 \\ 
            Breakout & 2 & 30 & 3 & 16 & 20 & 20 & \textbf{84} & 16 & 10 & 7 \\ 
            ChopperCommand & 811 & 7388 & 1005 & 979 & 946 & 1697 & 1565 & 1888 & \textbf{2222} & 1642 \\ 
            CrazyClimber & 10780 & 35829 & 14675 & 62584 & 36700 & 71820 & 59324 & 66776 & \textbf{86225} & 83931 \\ 
            DemonAttack & 152 & 1971 & 160 & 208 & 518 & 350 & \textbf{2034} & 165 & 577 & 201 \\ 
            Freeway & 0 & 30 & 2 & 17 & 19 & 24 & 31 & \textbf{34} & 0 & 15 \\ 
            Frostbite & 65 & 4335 & 127 & 237 & 1171 & 1476 & 259 & 1316 & \textbf{3377} & 785 \\ 
            Gopher & 258 & 2412 & 368 & 597 & 661 & 1675 & 2236 & \textbf{8240} & 2160 & 2757 \\ 
            Hero & 1027 & 30826 & 2596 & 2657 & 5859 & 7254 & 7037 & 11044 & \textbf{13354} & 7946 \\ 
            Jamesbond & 29 & 303 & 41 & 100 & 366 & 362 & 463 & 509 & \textbf{540} & 372 \\ 
            Kangaroo & 52 & 3035 & 55 & 51 & 3617 & 1240 & 838 & \textbf{4208} & 2643 & 1384 \\ 
            Krull & 1598 & 2666 & 3222 & 2205 & 3682 & 6349 & 6616 & 8413 & 8171 & \textbf{9693} \\ 
            KungFuMaster & 258 & 22736 & 2090 & 14862 & 14783 & 24555 & 21760 & \textbf{26183} & 25900 & 23920 \\ 
            MsPacman & 307 & 6952 & 366 & 1480 & 1318 & 1588 & 999 & \textbf{2673} & 1521 & 2270 \\ 
            Pong & -21 & 15 & -20 & 13 & -5 & \textbf{19} & 15 & 11 & -4 & 15 \\ 
            PrivateEye & 25 & 69571 & 100 & 35 & 86 & 87 & 100 & \textbf{7781} & 3238 & 90 \\ 
            Qbert & 164 & 13455 & 317 & 1289 & 866 & 3331 & 746 & \textbf{4522} & 2921 & 796 \\ 
            RoadRunner & 12 & 7845 & 602 & 5641 & 12213 & 9109 & 9615 & 17564 & \textbf{19230} & 14020 \\ 
            Seaquest & 68 & 42055 & 305 & 683 & 558 & 774 & 661 & 525 & \textbf{962}& 497 \\ 
            UpNDown & 533 & 11693 & 1502 & 3350 & 10859 & 15982 & 3546 & 7985 & \textbf{46910} & 7387 \\
            \hline
            Normalised Mean (\%) & 0 & 100 & 11 & 33 & 62 & 96 & 105 & 127 & 125 & 105 \\ 
            Normalised Median (\%) & 0 & 100 & 3 & 13 & 40 & 51 & 29 & 58 & 49 & 27 \\ 
            \hline
        \end{tabular}
        }
        \caption{Comparison of game performance metrics for various algorithms across multiple Atari games. For \texttt{Freeway} IRIS enhances exploration using a distinct set of hyperparameters, while STORM leverages offline expert knowledge. TWM reports the results with a 21.6M model while IRIS does not report the exact number of parameters, they use the same transformer embedding dimension and layer number as TWM plus a behaviour policy with CNN layers. DreamerV3 notably uses a 200M parameter model and achieves good results in a series of diverse tasks. STORM does not report the number of trainable parameters.}
        \label{table:atari100k}
    \end{table}
\end{frame}

\begin{frame}
    \frametitle{Ablation 1/3: DFS}
    
    \textbf{DFS vs. Uniform Sampling:}
    \begin{itemize}
        \item DFS achieves 105\% normalized mean score (vs. uniform's 80\%)
        \item Similar median performance (27\% vs. 28\%)
        \item DFS shows significant advantages in games with evolving dynamics:
        \begin{itemize}
            \item \texttt{Alien}, \texttt{Asterix}, \texttt{BankHeist}, \texttt{Seaquest}
        \end{itemize}
        \item Strong performance in opponent-based games:
        \begin{itemize}
            \item \texttt{Boxing}, \texttt{Pong} (exploiting opponent AI weaknesses)
        \end{itemize}
        \item Less effective in games with early-accessible critical dynamics:
        \begin{itemize}
            \item \texttt{Breakout}, \texttt{KungFuMaster}
        \end{itemize}
    \end{itemize}
\end{frame}

\begin{frame}
    \frametitle{DFS vs. Uniform Sampling Performance}
    \begin{table}
        \centering
        \scalebox{0.78}{
        \begin{tabular}{lllrr}
        \hline
              Game &  Random &  Human &  DFS &  Uniform  \\
        \hline
             Alien &     228 &   7128 &      \textbf{820} &          696 \\
            Amidar &       6 &   1720 &      131 &          \textbf{154} \\
           Assault &     222 &    742 &      \textbf{539} &          511 \\
           Asterix &     210 &   8503 &     \textbf{1632} &         1045 \\
         BankHeist &      14 &    753 &      \textbf{137} &           52 \\
        BattleZone &    2360 &  37188 &    10860 &        \textbf{10900} \\
            Boxing &       0 &     12 &       \textbf{78} &           49 \\
          Breakout &       2 &     30 &        7 &           \textbf{11} \\
    ChopperCommand &     811 &   7388 &     \textbf{1642} &         1083 \\
      CrazyClimber &   10780 &  35829 &    \textbf{83931} &        77140 \\
       DemonAttack &     152 &   1971 &      \textbf{201} &          151 \\
           Freeway &       0 &     30 &       \textbf{15} &           15 \\
         Frostbite &      65 &   4335 &      785 &          \textbf{975} \\
            Gopher &     258 &   2412 &     \textbf{2757} &         2289 \\
              Hero &    1027 &  30826 &     \textbf{7946} &         7564 \\
         Jamesbond &      29 &    303 &      \textbf{372} &          363 \\
          Kangaroo &      52 &   3035 &     \textbf{1384} &          620 \\
             Krull &    1598 &   2666 &     \textbf{9693} &         7553 \\
      KungFuMaster &     258 &  22736 &    23920 &        \textbf{24030} \\
          MsPacman &     307 &   6952 &     2270 &         \textbf{2508} \\
              Pong &     -21 &     15 &       \textbf{15} &            3 \\
        PrivateEye &      25 &  69571 &       \textbf{90} &           76 \\
             Qbert &     164 &  13455 &      796 &          \textbf{939} \\
        RoadRunner &      12 &   7845 &    \textbf{14020} &         9328 \\
          Seaquest &      68 &  42055 &      \textbf{497} &          384 \\
           UpNDown &     533 &  11693 &     \textbf{7387} &         5756 \\
        \hline
        Normalised Mean (\%) & 0 & 100 & 105 & 80 \\ 
        Normalised Median (\%) & 0 & 100 & 27 & 28 \\ 
        \hline
        \end{tabular}
        }
        \label{table:dfs_vs_uniform}
    \end{table}
\end{frame}

\begin{frame}
    \frametitle{Ablation 2/3: Mamba vs. Mamba-2}

    Mamba-2 restricts the diagonal matrix $\displaystyle \mA$ for efficiency. We compare Mamba-2 and Mamba as world model backbones using identical hyperparameters with DFS.
    
    The following figure shows Mamba-2 outperforming Mamba in \texttt{Krull}, \texttt{Boxing} and \texttt{Freeway}. In \texttt{Krull}, Mamba plateaus when failing to rescue the princess, while Mamba-2 succeeds. In sparse-reward \texttt{Freeway}, only the DFS+Mamba-2 combination achieves positive results.
    
    \begin{figure}
        \centering
        \includegraphics[width=\textwidth]{figures/mamba1_vs_mamba2.png}
        \caption{Mamba vs. Mamba-2. Mamba2 has shown a superior performance to Mamba in three out of
four games. Both Mamba and Mamba-2 use DFS in this experiment.}
    \end{figure}
\end{frame}

\begin{frame}
    \frametitle{Ablation 3/3: Sequence models for long-sequence predictability tasks}
    
    \begin{columns}
        \begin{column}{0.6\textwidth}
            \textbf{Environment:}
            \begin{itemize}
                \item $5 \times 5$ grid with outer walls and $3 \times 3$ traversable area
                \item Red agent moves based on actions, yellow fixed goal
                \item Positions re-randomized when agent reaches goal
            \end{itemize}
            
            \textbf{Sequence Construction:}
            \begin{itemize}
                \item Each frame: $l_f = 5^2 + 1 = 26$ tokens (grid cells + action)
                \item Short sequence: $l = 8 \times l_f = 208$ tokens
                \item Long sequence: $l = 64 \times l_f = 1664$ tokens
            \end{itemize}
        \end{column}
        
        \begin{column}{0.4\textwidth}
            \textbf{Learning Objectives:}
            \begin{itemize}
                \item Reconstruct grid layout
                \item Track agent position based on movement history
                \item Capture long-term dependencies
            \end{itemize}
            
            \textbf{Models Compared:}
            \begin{itemize}
                \item Mamba-2 \& Mamba
                \item GRU
                \item Transformer
            \end{itemize}
        \end{column}
    \end{columns}
\end{frame}

\begin{frame}
    \frametitle{Grid World Experiment: Results}
    
    \begin{table}[!ht]
        \centering
        \renewcommand{\arraystretch}{1.1}
        \setlength{\tabcolsep}{6pt}
        \scriptsize
        \resizebox{\textwidth}{!}{
        \begin{tabular}{lccccc}
        \hline
        \textbf{Method} & \textbf{$l$} & \textbf{Training Time (ms)} & \textbf{Memory Usage (\%)} & \textbf{Error (\%)} \\ \hline
        \multirow{2}{*}{Mamba-2} 
            & 208  & 25   & 13  & $15.6 \pm 2.6$ \\ 
            & 1664 & 214  & 55  & $14.2 \pm 0.3$ \\ \hline
        \multirow{2}{*}{Mamba} 
            & 208  & 34   & 14  & $13.9 \pm 0.4$ \\ 
            & 1664 & 299  & 52  & $14.0 \pm 0.4$ \\ \hline
        \multirow{2}{*}{GRU} 
            & 208  & 75   & 66  & $21.3 \pm 0.3$ \\ 
            & 1664 & 628  & 68  & $34.7 \pm 25.4$ \\ \hline
        \multirow{2}{*}{Transformer} 
            & 208  & 45   & 17  & $75.0 \pm 1.1$ \\ 
            & 1664 & -    & OOM & - \\ \hline
        \end{tabular}
        }
        \caption{Performance comparison of different methods in the grid world environment. Memory usage is reported as a percentage of an 8GB GPU. The error is represented as the mean $\pm$ standard deviation. The training time refers to the average duration per training step. Notably, the Transformer encounters an out-of-memory (OOM) error during training with long sequences. All experiments are conducted on a laptop.}
        \label{tab:performance_comparison}
    \end{table}
    
    \vspace{0.3em}
    \textbf{Key Findings:}
    \begin{itemize}
        \item Mamba-2 shows best overall performance with lowest training time
        \item Both Mamba variants maintain low reconstruction error on long sequences
        \item GRU shows increased error and training time with longer sequences
        \item Transformer runs out of memory (OOM) on long sequences
        \item Results confirm Mamba-based models' strong capability for long-sequence modeling in MBRL
    \end{itemize}
\end{frame}







\end{document}